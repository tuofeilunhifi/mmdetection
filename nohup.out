/home/yunji.cjy/anaconda3/envs/openmmlab/lib/python3.7/site-packages/torch/distributed/launch.py:186: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  FutureWarning,
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
/home/yunji.cjy/codebase/mmdetection/mmdet/utils/setup_env.py:43: UserWarning: Setting MKL_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
  f'Setting MKL_NUM_THREADS environment variable for each process '
/home/yunji.cjy/codebase/mmdetection/mmdet/utils/setup_env.py:43: UserWarning: Setting MKL_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
  f'Setting MKL_NUM_THREADS environment variable for each process '
/home/yunji.cjy/codebase/mmdetection/mmdet/utils/setup_env.py:43: UserWarning: Setting MKL_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
  f'Setting MKL_NUM_THREADS environment variable for each process '
/home/yunji.cjy/codebase/mmdetection/mmdet/utils/setup_env.py:43: UserWarning: Setting MKL_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
  f'Setting MKL_NUM_THREADS environment variable for each process '
/home/yunji.cjy/codebase/mmdetection/mmdet/utils/setup_env.py:43: UserWarning: Setting MKL_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
  f'Setting MKL_NUM_THREADS environment variable for each process '
/home/yunji.cjy/codebase/mmdetection/mmdet/utils/setup_env.py:43: UserWarning: Setting MKL_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
  f'Setting MKL_NUM_THREADS environment variable for each process '
/home/yunji.cjy/codebase/mmdetection/mmdet/utils/setup_env.py:43: UserWarning: Setting MKL_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
  f'Setting MKL_NUM_THREADS environment variable for each process '
/home/yunji.cjy/codebase/mmdetection/mmdet/utils/setup_env.py:43: UserWarning: Setting MKL_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
  f'Setting MKL_NUM_THREADS environment variable for each process '
2022-04-15 11:33:25,382 - mmdet - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.7.13 (default, Mar 29 2022, 02:18:16) [GCC 7.5.0]
CUDA available: True
GPU 0,1,2,3,4,5,6,7: Tesla V100-SXM2-16GB
CUDA_HOME: /usr/local/cuda
NVCC: Cuda compilation tools, release 10.2, V10.2.89
GCC: gcc (GCC) 4.8.5 20150623 (Red Hat 4.8.5-28)
PyTorch: 1.10.0
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=10.2, CUDNN_VERSION=7.6.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

TorchVision: 0.11.0
OpenCV: 4.5.5
MMCV: 1.4.8
MMCV Compiler: GCC 7.3
MMCV CUDA Compiler: 10.2
MMDetection: 2.23.0+aaa0ce0
------------------------------------------------------------

2022-04-15 11:33:26,166 - mmdet - INFO - Distributed training: True
2022-04-15 11:33:26,944 - mmdet - INFO - Config:
norm_cfg = dict(type='SyncBN', requires_grad=True)
head_norm_cfg = dict(type='MMSyncBN', requires_grad=True)
model = dict(
    type='MaskRCNN',
    backbone=dict(
        type='ViTDetVisionTransformer',
        arch='b',
        img_size=1024,
        patch_size=16,
        window_size=16,
        drop_path_rate=0.1,
        out_indices=[11],
        final_norm=True,
        sincos_pos_embed=False,
        use_rel_pos_bias=True,
        init_cfg=dict(
            type='Pretrained',
            checkpoint=
            '/home/yunji.cjy/pretrain/warpper_mae_vit-base-p16-1600e.pth')),
    neck=dict(
        type='SFP',
        in_channels=768,
        out_channels=256,
        norm_cfg=dict(type='LN')),
    rpn_head=dict(
        type='RPNHead',
        in_channels=256,
        feat_channels=256,
        num_convs=2,
        anchor_generator=dict(
            type='AnchorGenerator',
            scales=[8],
            ratios=[0.5, 1.0, 2.0],
            strides=[4, 8, 16, 32]),
        bbox_coder=dict(
            type='DeltaXYWHBBoxCoder',
            target_means=[0.0, 0.0, 0.0, 0.0],
            target_stds=[1.0, 1.0, 1.0, 1.0]),
        loss_cls=dict(
            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),
        loss_bbox=dict(type='L1Loss', loss_weight=1.0)),
    roi_head=dict(
        type='StandardRoIHead',
        bbox_roi_extractor=dict(
            type='SingleRoIExtractor',
            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=0),
            out_channels=256,
            featmap_strides=[4, 8, 16, 32]),
        bbox_head=dict(
            type='Shared4Conv1FCBBoxHead',
            conv_out_channels=256,
            norm_cfg=dict(type='MMSyncBN', requires_grad=True),
            in_channels=256,
            fc_out_channels=1024,
            roi_feat_size=7,
            num_classes=80,
            bbox_coder=dict(
                type='DeltaXYWHBBoxCoder',
                target_means=[0.0, 0.0, 0.0, 0.0],
                target_stds=[0.1, 0.1, 0.2, 0.2]),
            reg_class_agnostic=False,
            loss_cls=dict(
                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0),
            loss_bbox=dict(type='L1Loss', loss_weight=1.0)),
        mask_roi_extractor=dict(
            type='SingleRoIExtractor',
            roi_layer=dict(type='RoIAlign', output_size=14, sampling_ratio=0),
            out_channels=256,
            featmap_strides=[4, 8, 16, 32]),
        mask_head=dict(
            type='FCNMaskHead',
            norm_cfg=dict(type='MMSyncBN', requires_grad=True),
            num_convs=4,
            in_channels=256,
            conv_out_channels=256,
            num_classes=80,
            loss_mask=dict(
                type='CrossEntropyLoss', use_mask=True, loss_weight=1.0))),
    train_cfg=dict(
        rpn=dict(
            assigner=dict(
                type='MaxIoUAssigner',
                pos_iou_thr=0.7,
                neg_iou_thr=0.3,
                min_pos_iou=0.3,
                match_low_quality=True,
                ignore_iof_thr=-1),
            sampler=dict(
                type='RandomSampler',
                num=256,
                pos_fraction=0.5,
                neg_pos_ub=-1,
                add_gt_as_proposals=False),
            allowed_border=-1,
            pos_weight=-1,
            debug=False),
        rpn_proposal=dict(
            nms_pre=2000,
            max_per_img=1000,
            nms=dict(type='nms', iou_threshold=0.7),
            min_bbox_size=0),
        rcnn=dict(
            assigner=dict(
                type='MaxIoUAssigner',
                pos_iou_thr=0.5,
                neg_iou_thr=0.5,
                min_pos_iou=0.5,
                match_low_quality=True,
                ignore_iof_thr=-1),
            sampler=dict(
                type='RandomSampler',
                num=512,
                pos_fraction=0.25,
                neg_pos_ub=-1,
                add_gt_as_proposals=True),
            mask_size=28,
            pos_weight=-1,
            debug=False)),
    test_cfg=dict(
        rpn=dict(
            nms_pre=1000,
            max_per_img=1000,
            nms=dict(type='nms', iou_threshold=0.7),
            min_bbox_size=0),
        rcnn=dict(
            score_thr=0.05,
            nms=dict(type='nms', iou_threshold=0.5),
            max_per_img=100,
            mask_thr_binary=0.5)))
dataset_type = 'CocoDataset'
data_root = '/home/yunji.cjy/data/coco/'
img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
image_size = (1024, 1024)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),
    dict(
        type='Resize',
        img_scale=(1024, 1024),
        ratio_range=(0.1, 2.0),
        multiscale_mode='range',
        keep_ratio=True),
    dict(
        type='RandomCrop',
        crop_type='absolute_range',
        crop_size=(1024, 1024),
        recompute_bbox=True,
        allow_negative_crop=True),
    dict(type='FilterAnnotations', min_gt_bbox_wh=(0.01, 0.01)),
    dict(type='RandomFlip', flip_ratio=0.5),
    dict(
        type='Normalize',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='Pad', size=(1024, 1024)),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels', 'gt_masks'])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(1024, 1024),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='RandomFlip'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='Pad', size=(1024, 1024)),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ])
]
data = dict(
    samples_per_gpu=2,
    workers_per_gpu=2,
    train=dict(
        type='RepeatDataset',
        times=4,
        dataset=dict(
            type='CocoDataset',
            ann_file=
            '/home/yunji.cjy/data/coco/annotations/instances_train2017.json',
            img_prefix='/home/yunji.cjy/data/coco/train2017/',
            pipeline=[
                dict(type='LoadImageFromFile'),
                dict(type='LoadAnnotations', with_bbox=True, with_mask=True),
                dict(
                    type='Resize',
                    img_scale=(1024, 1024),
                    ratio_range=(0.1, 2.0),
                    multiscale_mode='range',
                    keep_ratio=True),
                dict(
                    type='RandomCrop',
                    crop_type='absolute_range',
                    crop_size=(1024, 1024),
                    recompute_bbox=True,
                    allow_negative_crop=True),
                dict(type='FilterAnnotations', min_gt_bbox_wh=(0.01, 0.01)),
                dict(type='RandomFlip', flip_ratio=0.5),
                dict(
                    type='Normalize',
                    mean=[123.675, 116.28, 103.53],
                    std=[58.395, 57.12, 57.375],
                    to_rgb=True),
                dict(type='Pad', size=(1024, 1024)),
                dict(type='DefaultFormatBundle'),
                dict(
                    type='Collect',
                    keys=['img', 'gt_bboxes', 'gt_labels', 'gt_masks'])
            ])),
    val=dict(
        type='CocoDataset',
        ann_file='/home/yunji.cjy/data/coco/annotations/instances_val2017.json',
        img_prefix='/home/yunji.cjy/data/coco/val2017/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(1024, 1024),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='Pad', size=(1024, 1024)),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]),
    test=dict(
        type='CocoDataset',
        ann_file='/home/yunji.cjy/data/coco/annotations/instances_val2017.json',
        img_prefix='/home/yunji.cjy/data/coco/val2017/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(1024, 1024),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='Pad', size=(1024, 1024)),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]))
evaluation = dict(interval=1, metric=['bbox', 'segm'])
paramwise_cfg = dict(
    norm=dict(weight_decay=0.0),
    bias=dict(weight_decay=0.0),
    pos_embed=dict(weight_decay=0.0),
    cls_token=dict(weight_decay=0.0))
optimizer = dict(
    type='AdamW',
    lr=0.0001,
    betas=(0.9, 0.999),
    weight_decay=0.1,
    constructor='TransformerFinetuneConstructor',
    model_type='vit',
    layer_decay=0.7,
    paramwise_cfg=dict(
        norm=dict(weight_decay=0.0),
        bias=dict(weight_decay=0.0),
        pos_embed=dict(weight_decay=0.0),
        cls_token=dict(weight_decay=0.0)))
cumulative_iters = 4
optimizer_config = dict(grad_clip=None, cumulative_iters=4)
lr_config = dict(
    policy='step',
    warmup='linear',
    warmup_iters=1000,
    warmup_ratio=0.001,
    step=[22, 24])
runner = dict(type='EpochBasedRunner', max_epochs=25)
fp16 = dict(loss_scale=dict(init_scale=512))
checkpoint_config = dict(interval=5)
log_config = dict(interval=50, hooks=[dict(type='TextLoggerHook')])
custom_hooks = [dict(type='NumClassCheckHook')]
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = None
resume_from = None
workflow = [('train', 1)]
opencv_num_threads = 0
mp_start_method = 'fork'
find_unused_parameters = True
work_dir = './work_dirs/vitdet_sfp_100e_fp16_coco'
auto_resume = False
gpu_ids = range(0, 8)

2022-04-15 11:33:33,034 - mmdet - INFO - Set random seed to 486155617, deterministic: False
/home/yunji.cjy/anaconda3/envs/openmmlab/lib/python3.7/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1634272126608/work/aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/home/yunji.cjy/anaconda3/envs/openmmlab/lib/python3.7/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1634272126608/work/aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/home/yunji.cjy/anaconda3/envs/openmmlab/lib/python3.7/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1634272126608/work/aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/home/yunji.cjy/anaconda3/envs/openmmlab/lib/python3.7/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1634272126608/work/aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/home/yunji.cjy/anaconda3/envs/openmmlab/lib/python3.7/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1634272126608/work/aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/home/yunji.cjy/anaconda3/envs/openmmlab/lib/python3.7/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1634272126608/work/aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/home/yunji.cjy/anaconda3/envs/openmmlab/lib/python3.7/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1634272126608/work/aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/home/yunji.cjy/anaconda3/envs/openmmlab/lib/python3.7/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1634272126608/work/aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
2022-04-15 11:33:35,295 - mmdet - INFO - initialize ViTDetVisionTransformer with init_cfg {'type': 'Pretrained', 'checkpoint': '/home/yunji.cjy/pretrain/warpper_mae_vit-base-p16-1600e.pth'}
2022-04-15 11:33:35,296 - mmcv - INFO - load model from: /home/yunji.cjy/pretrain/warpper_mae_vit-base-p16-1600e.pth
2022-04-15 11:33:35,296 - mmcv - INFO - load checkpoint from local path: /home/yunji.cjy/pretrain/warpper_mae_vit-base-p16-1600e.pth
2022-04-15 11:33:35,568 - mmdet - INFO - Resize the pos_embed shape from torch.Size([1, 197, 768]) to torch.Size([1, 4097, 768]).
2022-04-15 11:33:35,753 - mmcv - WARNING - The model and loaded state dict do not match exactly

missing keys in source state_dict: window_rel_pos_bias.relative_position_bias_table, window_rel_pos_bias.relative_position_index, global_rel_pos_bias.relative_position_bias_table, global_rel_pos_bias.relative_position_index

2022-04-15 11:33:35,886 - mmdet - INFO - initialize SFP with init_cfg [{'type': 'Xavier', 'layer': ['Conv2d', 'ConvTranspose2d'], 'distribution': 'uniform'}, {'type': 'Constant', 'layer': ['GroupNorm'], 'val': 1}]
2022-04-15 11:33:35,976 - mmdet - INFO - initialize RPNHead with init_cfg {'type': 'Normal', 'layer': 'Conv2d', 'std': 0.01}
2022-04-15 11:33:35,987 - mmdet - INFO - initialize Shared4Conv1FCBBoxHead with init_cfg [{'type': 'Normal', 'std': 0.01, 'override': {'name': 'fc_cls'}}, {'type': 'Normal', 'std': 0.001, 'override': {'name': 'fc_reg'}}, {'type': 'Xavier', 'distribution': 'uniform', 'override': [{'name': 'shared_fcs'}, {'name': 'cls_fcs'}, {'name': 'reg_fcs'}]}]
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
2022-04-15 11:33:36,152 - mmdet - INFO - model:MaskRCNN(
  (backbone): ViTDetVisionTransformer(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))
      (norm): Identity()
    )
    (window_rel_pos_bias): RelativePositionBias()
    (global_rel_pos_bias): RelativePositionBias()
    (drop_after_pos): Dropout(p=0.0, inplace=False)
    (blocks): ModuleList(
      (0): Block(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (drop1): Dropout(p=0.0, inplace=False)
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
      )
      (1): Block(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (drop1): Dropout(p=0.0, inplace=False)
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
      )
      (2): Block(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (drop1): Dropout(p=0.0, inplace=False)
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
      )
      (3): Block(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (drop1): Dropout(p=0.0, inplace=False)
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
      )
      (4): Block(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (drop1): Dropout(p=0.0, inplace=False)
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
      )
      (5): Block(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (drop1): Dropout(p=0.0, inplace=False)
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
      )
      (6): Block(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (drop1): Dropout(p=0.0, inplace=False)
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
      )
      (7): Block(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (drop1): Dropout(p=0.0, inplace=False)
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
      )
      (8): Block(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (drop1): Dropout(p=0.0, inplace=False)
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
      )
      (9): Block(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (drop1): Dropout(p=0.0, inplace=False)
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
      )
      (10): Block(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (drop1): Dropout(p=0.0, inplace=False)
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
      )
      (11): Block(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (drop1): Dropout(p=0.0, inplace=False)
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  init_cfg={'type': 'Pretrained', 'checkpoint': '/home/yunji.cjy/pretrain/warpper_mae_vit-base-p16-1600e.pth'}
  (neck): SFP(
    (top_downs): ModuleList(
      (0): Sequential(
        (0): ConvTranspose2d(768, 768, kernel_size=(2, 2), stride=(2, 2))
        (1): GroupNorm(1, 768, eps=1e-06, affine=True)
        (2): GELU()
        (3): ConvTranspose2d(768, 768, kernel_size=(2, 2), stride=(2, 2))
      )
      (1): ConvTranspose2d(768, 768, kernel_size=(2, 2), stride=(2, 2))
      (2): Identity()
      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (sfp_outs): ModuleList(
      (0): Sequential(
        (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))
        (1): GroupNorm(1, 256, eps=1e-06, affine=True)
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): GroupNorm(1, 256, eps=1e-06, affine=True)
      )
      (1): Sequential(
        (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))
        (1): GroupNorm(1, 256, eps=1e-06, affine=True)
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): GroupNorm(1, 256, eps=1e-06, affine=True)
      )
      (2): Sequential(
        (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))
        (1): GroupNorm(1, 256, eps=1e-06, affine=True)
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): GroupNorm(1, 256, eps=1e-06, affine=True)
      )
      (3): Sequential(
        (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))
        (1): GroupNorm(1, 256, eps=1e-06, affine=True)
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): GroupNorm(1, 256, eps=1e-06, affine=True)
      )
    )
  )
  init_cfg=[{'type': 'Xavier', 'layer': ['Conv2d', 'ConvTranspose2d'], 'distribution': 'uniform'}, {'type': 'Constant', 'layer': ['GroupNorm'], 'val': 1}]
  (rpn_head): RPNHead(
    (loss_cls): CrossEntropyLoss(avg_non_ignore=False)
    (loss_bbox): L1Loss()
    (rpn_conv): Sequential(
      (0): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (activate): ReLU()
      )
      (1): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (activate): ReLU()
      )
    )
    (rpn_cls): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
    (rpn_reg): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
  )
  init_cfg={'type': 'Normal', 'layer': 'Conv2d', 'std': 0.01}
  (roi_head): StandardRoIHead(
    (bbox_roi_extractor): SingleRoIExtractor(
      (roi_layers): ModuleList(
        (0): RoIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, pool_mode=avg, aligned=True, use_torchvision=False)
        (1): RoIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, pool_mode=avg, aligned=True, use_torchvision=False)
        (2): RoIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, pool_mode=avg, aligned=True, use_torchvision=False)
        (3): RoIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, pool_mode=avg, aligned=True, use_torchvision=False)
      )
    )
    (bbox_head): Shared4Conv1FCBBoxHead(
      (loss_cls): CrossEntropyLoss(avg_non_ignore=False)
      (loss_bbox): L1Loss()
      (fc_cls): Linear(in_features=1024, out_features=81, bias=True)
      (fc_reg): Linear(in_features=1024, out_features=320, bias=True)
      (shared_convs): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, group_size=8,stats_mode=default)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, group_size=8,stats_mode=default)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, group_size=8,stats_mode=default)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, group_size=8,stats_mode=default)
          (activate): ReLU(inplace=True)
        )
      )
      (shared_fcs): ModuleList(
        (0): Linear(in_features=12544, out_features=1024, bias=True)
      )
      (cls_convs): ModuleList()
      (cls_fcs): ModuleList()
      (reg_convs): ModuleList()
      (reg_fcs): ModuleList()
      (relu): ReLU(inplace=True)
    )
    init_cfg=[{'type': 'Normal', 'std': 0.01, 'override': {'name': 'fc_cls'}}, {'type': 'Normal', 'std': 0.001, 'override': {'name': 'fc_reg'}}, {'type': 'Xavier', 'distribution': 'uniform', 'override': [{'name': 'shared_fcs'}, {'name': 'cls_fcs'}, {'name': 'reg_fcs'}]}]
    (mask_roi_extractor): SingleRoIExtractor(
      (roi_layers): ModuleList(
        (0): RoIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, pool_mode=avg, aligned=True, use_torchvision=False)
        (1): RoIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, pool_mode=avg, aligned=True, use_torchvision=False)
        (2): RoIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, pool_mode=avg, aligned=True, use_torchvision=False)
        (3): RoIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, pool_mode=avg, aligned=True, use_torchvision=False)
      )
    )
    (mask_head): FCNMaskHead(
      (loss_mask): CrossEntropyLoss(avg_non_ignore=False)
      (convs): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, group_size=8,stats_mode=default)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, group_size=8,stats_mode=default)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, group_size=8,stats_mode=default)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, group_size=8,stats_mode=default)
          (activate): ReLU(inplace=True)
        )
      )
      (upsample): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (conv_logits): Conv2d(256, 80, kernel_size=(1, 1), stride=(1, 1))
      (relu): ReLU(inplace=True)
    )
  )
)
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
Done (t=18.54s)
creating index...
Done (t=18.54s)
creating index...
Done (t=18.55s)
creating index...
Done (t=18.62s)
creating index...
Done (t=18.64s)
creating index...
Done (t=18.65s)
creating index...
Done (t=18.63s)
creating index...
Done (t=18.63s)
creating index...
index created!
index created!
index created!
index created!
index created!
index created!
index created!
index created!
paramwise_options --                                     backbone.cls_token: weight_decay=0.0
paramwise_options --                                     backbone.cls_token: lr=9.688901040699993e-07
paramwise_options --                                     backbone.pos_embed: weight_decay=0.0
paramwise_options --                                     backbone.pos_embed: lr=9.688901040699993e-07
paramwise_options --                                     backbone.patch_embed.proj.weight: lr=9.688901040699993e-07
paramwise_options --                                     backbone.patch_embed.proj.bias: weight_decay=0.0
paramwise_options --                                     backbone.patch_embed.proj.bias: lr=9.688901040699993e-07
paramwise_options --                                     backbone.window_rel_pos_bias.relative_position_bias_table: weight_decay=0.0
paramwise_options --                                     backbone.global_rel_pos_bias.relative_position_bias_table: weight_decay=0.0
paramwise_options --                                     backbone.blocks.0.norm1.weight: weight_decay=0.0
paramwise_options --                                     backbone.blocks.0.norm1.weight: lr=1.384128720099999e-06
paramwise_options --                                     backbone.blocks.0.norm1.bias: weight_decay=0.0
paramwise_options --                                     backbone.blocks.0.norm1.bias: weight_decay=0.0
paramwise_options --                                     backbone.blocks.0.norm1.bias: lr=1.384128720099999e-06
paramwise_options --                                     backbone.blocks.0.attn.qkv.weight: lr=1.384128720099999e-06
paramwise_options --                                     backbone.blocks.0.attn.qkv.bias: weight_decay=0.0
paramwise_options --                                     backbone.blocks.0.attn.qkv.bias: lr=1.384128720099999e-06
paramwise_options --                                     backbone.blocks.0.attn.proj.weight: lr=1.384128720099999e-06
paramwise_options --                                     backbone.blocks.0.attn.proj.bias: weight_decay=0.0
paramwise_options --                                     backbone.blocks.0.attn.proj.bias: lr=1.384128720099999e-06
paramwise_options --                                     backbone.blocks.0.norm2.weight: weight_decay=0.0
paramwise_options --                                     backbone.blocks.0.norm2.weight: lr=1.384128720099999e-06
paramwise_options --                                     backbone.blocks.0.norm2.bias: weight_decay=0.0
paramwise_options --                                     backbone.blocks.0.norm2.bias: weight_decay=0.0
paramwise_options --                                     backbone.blocks.0.norm2.bias: lr=1.384128720099999e-06
paramwise_options --                                     backbone.blocks.0.mlp.fc1.weight: lr=1.384128720099999e-06
paramwise_options --                                     backbone.blocks.0.mlp.fc1.bias: weight_decay=0.0
paramwise_options --                                     backbone.blocks.0.mlp.fc1.bias: lr=1.384128720099999e-06
paramwise_options --                                     backbone.blocks.0.mlp.fc2.weight: lr=1.384128720099999e-06
paramwise_options --                                     backbone.blocks.0.mlp.fc2.bias: weight_decay=0.0
paramwise_options --                                     backbone.blocks.0.mlp.fc2.bias: lr=1.384128720099999e-06
paramwise_options --                                     backbone.blocks.1.norm1.weight: weight_decay=0.0
paramwise_options --                                     backbone.blocks.1.norm1.weight: lr=1.977326742999999e-06
paramwise_options --                                     backbone.blocks.1.norm1.bias: weight_decay=0.0
paramwise_options --                                     backbone.blocks.1.norm1.bias: weight_decay=0.0
paramwise_options --                                     backbone.blocks.1.norm1.bias: lr=1.977326742999999e-06
paramwise_options --                                     backbone.blocks.1.attn.qkv.weight: lr=1.977326742999999e-06
paramwise_options --                                     backbone.blocks.1.attn.qkv.bias: weight_decay=0.0
paramwise_options --                                     backbone.blocks.1.attn.qkv.bias: lr=1.977326742999999e-06
paramwise_options --                                     backbone.blocks.1.attn.proj.weight: lr=1.977326742999999e-06
paramwise_options --                                     backbone.blocks.1.attn.proj.bias: weight_decay=0.0
paramwise_options --                                     backbone.blocks.1.attn.proj.bias: lr=1.977326742999999e-06
paramwise_options --                                     backbone.blocks.1.norm2.weight: weight_decay=0.0
paramwise_options --                                     backbone.blocks.1.norm2.weight: lr=1.977326742999999e-06
paramwise_options --                                     backbone.blocks.1.norm2.bias: weight_decay=0.0
paramwise_options --                                     backbone.blocks.1.norm2.bias: weight_decay=0.0
paramwise_options --                                     backbone.blocks.1.norm2.bias: lr=1.977326742999999e-06
paramwise_options --                                     backbone.blocks.1.mlp.fc1.weight: lr=1.977326742999999e-06
paramwise_options --                                     backbone.blocks.1.mlp.fc1.bias: weight_decay=0.0
paramwise_options --                                     backbone.blocks.1.mlp.fc1.bias: lr=1.977326742999999e-06
paramwise_options --                                     backbone.blocks.1.mlp.fc2.weight: lr=1.977326742999999e-06
paramwise_options --                                     backbone.blocks.1.mlp.fc2.bias: weight_decay=0.0
paramwise_options --                                     backbone.blocks.1.mlp.fc2.bias: lr=1.977326742999999e-06
paramwise_options --                                     backbone.blocks.2.norm1.weight: weight_decay=0.0
paramwise_options --                                     backbone.blocks.2.norm1.weight: lr=2.8247524899999986e-06
paramwise_options --                                     backbone.blocks.2.norm1.bias: weight_decay=0.0
paramwise_options --                                     backbone.blocks.2.norm1.bias: weight_decay=0.0
paramwise_options --                                     backbone.blocks.2.norm1.bias: lr=2.8247524899999986e-06
paramwise_options --                                     backbone.blocks.2.attn.qkv.weight: lr=2.8247524899999986e-06
paramwise_options --                                     backbone.blocks.2.attn.qkv.bias: weight_decay=0.0
paramwise_options --                                     backbone.blocks.2.attn.qkv.bias: lr=2.8247524899999986e-06
paramwise_options --                                     backbone.blocks.2.attn.proj.weight: lr=2.8247524899999986e-06
paramwise_options --                                     backbone.blocks.2.attn.proj.bias: weight_decay=0.0
paramwise_options --                                     backbone.blocks.2.attn.proj.bias: lr=2.8247524899999986e-06
paramwise_options --                                     backbone.blocks.2.norm2.weight: weight_decay=0.0
paramwise_options --                                     backbone.blocks.2.norm2.weight: lr=2.8247524899999986e-06
paramwise_options --                                     backbone.blocks.2.norm2.bias: weight_decay=0.0
paramwise_options --                                     backbone.blocks.2.norm2.bias: weight_decay=0.0
paramwise_options --                                     backbone.blocks.2.norm2.bias: lr=2.8247524899999986e-06
paramwise_options --                                     backbone.blocks.2.mlp.fc1.weight: lr=2.8247524899999986e-06
paramwise_options --                                     backbone.blocks.2.mlp.fc1.bias: weight_decay=0.0
paramwise_options --                                     backbone.blocks.2.mlp.fc1.bias: lr=2.8247524899999986e-06
paramwise_options --                                     backbone.blocks.2.mlp.fc2.weight: lr=2.8247524899999986e-06
paramwise_options --                                     backbone.blocks.2.mlp.fc2.bias: weight_decay=0.0
paramwise_options --                                     backbone.blocks.2.mlp.fc2.bias: lr=2.8247524899999986e-06
paramwise_options --                                     backbone.blocks.3.norm1.weight: weight_decay=0.0
paramwise_options --                                     backbone.blocks.3.norm1.weight: lr=4.035360699999998e-06
paramwise_options --                                     backbone.blocks.3.norm1.bias: weight_decay=0.0
paramwise_options --                                     backbone.blocks.3.norm1.bias: weight_decay=0.0
paramwise_options --                                     backbone.blocks.3.norm1.bias: lr=4.035360699999998e-06
paramwise_options --                                     backbone.blocks.3.attn.qkv.weight: lr=4.035360699999998e-06
paramwise_options --                                     backbone.blocks.3.attn.qkv.bias: weight_decay=0.0
paramwise_options --                                     backbone.blocks.3.attn.qkv.bias: lr=4.035360699999998e-06
paramwise_options --                                     backbone.blocks.3.attn.proj.weight: lr=4.035360699999998e-06
paramwise_options --                                     backbone.blocks.3.attn.proj.bias: weight_decay=0.0
paramwise_options --                                     backbone.blocks.3.attn.proj.bias: lr=4.035360699999998e-06
paramwise_options --                                     backbone.blocks.3.norm2.weight: weight_decay=0.0
paramwise_options --                                     backbone.blocks.3.norm2.weight: lr=4.035360699999998e-06
paramwise_options --                                     backbone.blocks.3.norm2.bias: weight_decay=0.0
paramwise_options --                                     backbone.blocks.3.norm2.bias: weight_decay=0.0
paramwise_options --                                     backbone.blocks.3.norm2.bias: lr=4.035360699999998e-06
paramwise_options --                                     backbone.blocks.3.mlp.fc1.weight: lr=4.035360699999998e-06
paramwise_options --                                     backbone.blocks.3.mlp.fc1.bias: weight_decay=0.0
paramwise_options --                                     backbone.blocks.3.mlp.fc1.bias: lr=4.035360699999998e-06
paramwise_options --                                     backbone.blocks.3.mlp.fc2.weight: lr=4.035360699999998e-06
paramwise_options --                                     backbone.blocks.3.mlp.fc2.bias: weight_decay=0.0
paramwise_options --                                     backbone.blocks.3.mlp.fc2.bias: lr=4.035360699999998e-06
paramwise_options --                                     backbone.blocks.4.norm1.weight: weight_decay=0.0
paramwise_options --                                     backbone.blocks.4.norm1.weight: lr=5.764800999999997e-06
paramwise_options --                                     backbone.blocks.4.norm1.bias: weight_decay=0.0
paramwise_options --                                     backbone.blocks.4.norm1.bias: weight_decay=0.0
paramwise_options --                                     backbone.blocks.4.norm1.bias: lr=5.764800999999997e-06
paramwise_options --                                     backbone.blocks.4.attn.qkv.weight: lr=5.764800999999997e-06
paramwise_options --                                     backbone.blocks.4.attn.qkv.bias: weight_decay=0.0
paramwise_options --                                     backbone.blocks.4.attn.qkv.bias: lr=5.764800999999997e-06
paramwise_options --                                     backbone.blocks.4.attn.proj.weight: lr=5.764800999999997e-06
paramwise_options --                                     backbone.blocks.4.attn.proj.bias: weight_decay=0.0
paramwise_options --                                     backbone.blocks.4.attn.proj.bias: lr=5.764800999999997e-06
paramwise_options --                                     backbone.blocks.4.norm2.weight: weight_decay=0.0
paramwise_options --                                     backbone.blocks.4.norm2.weight: lr=5.764800999999997e-06
paramwise_options --                                     backbone.blocks.4.norm2.bias: weight_decay=0.0
paramwise_options --                                     backbone.blocks.4.norm2.bias: weight_decay=0.0
paramwise_options --                                     backbone.blocks.4.norm2.bias: lr=5.764800999999997e-06
paramwise_options --                                     backbone.blocks.4.mlp.fc1.weight: lr=5.764800999999997e-06
paramwise_options --                                     backbone.blocks.4.mlp.fc1.bias: weight_decay=0.0
paramwise_options --                                     backbone.blocks.4.mlp.fc1.bias: lr=5.764800999999997e-06
paramwise_options --                                     backbone.blocks.4.mlp.fc2.weight: lr=5.764800999999997e-06
paramwise_options --                                     backbone.blocks.4.mlp.fc2.bias: weight_decay=0.0
paramwise_options --                                     backbone.blocks.4.mlp.fc2.bias: lr=5.764800999999997e-06
paramwise_options --                                     backbone.blocks.5.norm1.weight: weight_decay=0.0
paramwise_options --                                     backbone.blocks.5.norm1.weight: lr=8.235429999999996e-06
paramwise_options --                                     backbone.blocks.5.norm1.bias: weight_decay=0.0
paramwise_options --                                     backbone.blocks.5.norm1.bias: weight_decay=0.0
paramwise_options --                                     backbone.blocks.5.norm1.bias: lr=8.235429999999996e-06
paramwise_options --                                     backbone.blocks.5.attn.qkv.weight: lr=8.235429999999996e-06
paramwise_options --                                     backbone.blocks.5.attn.qkv.bias: weight_decay=0.0
paramwise_options --                                     backbone.blocks.5.attn.qkv.bias: lr=8.235429999999996e-06
paramwise_options --                                     backbone.blocks.5.attn.proj.weight: lr=8.235429999999996e-06
paramwise_options --                                     backbone.blocks.5.attn.proj.bias: weight_decay=0.0
paramwise_options --                                     backbone.blocks.5.attn.proj.bias: lr=8.235429999999996e-06
paramwise_options --                                     backbone.blocks.5.norm2.weight: weight_decay=0.0
paramwise_options --                                     backbone.blocks.5.norm2.weight: lr=8.235429999999996e-06
paramwise_options --                                     backbone.blocks.5.norm2.bias: weight_decay=0.0
paramwise_options --                                     backbone.blocks.5.norm2.bias: weight_decay=0.0
paramwise_options --                                     backbone.blocks.5.norm2.bias: lr=8.235429999999996e-06
paramwise_options --                                     backbone.blocks.5.mlp.fc1.weight: lr=8.235429999999996e-06
paramwise_options --                                     backbone.blocks.5.mlp.fc1.bias: weight_decay=0.0
paramwise_options --                                     backbone.blocks.5.mlp.fc1.bias: lr=8.235429999999996e-06
paramwise_options --                                     backbone.blocks.5.mlp.fc2.weight: lr=8.235429999999996e-06
paramwise_options --                                     backbone.blocks.5.mlp.fc2.bias: weight_decay=0.0
paramwise_options --                                     backbone.blocks.5.mlp.fc2.bias: lr=8.235429999999996e-06
paramwise_options --                                     backbone.blocks.6.norm1.weight: weight_decay=0.0
paramwise_options --                                     backbone.blocks.6.norm1.weight: lr=1.1764899999999996e-05
paramwise_options --                                     backbone.blocks.6.norm1.bias: weight_decay=0.0
paramwise_options --                                     backbone.blocks.6.norm1.bias: weight_decay=0.0
paramwise_options --                                     backbone.blocks.6.norm1.bias: lr=1.1764899999999996e-05
paramwise_options --                                     backbone.blocks.6.attn.qkv.weight: lr=1.1764899999999996e-05
paramwise_options --                                     backbone.blocks.6.attn.qkv.bias: weight_decay=0.0
paramwise_options --                                     backbone.blocks.6.attn.qkv.bias: lr=1.1764899999999996e-05
paramwise_options --                                     backbone.blocks.6.attn.proj.weight: lr=1.1764899999999996e-05
paramwise_options --                                     backbone.blocks.6.attn.proj.bias: weight_decay=0.0
paramwise_options --                                     backbone.blocks.6.attn.proj.bias: lr=1.1764899999999996e-05
paramwise_options --                                     backbone.blocks.6.norm2.weight: weight_decay=0.0
paramwise_options --                                     backbone.blocks.6.norm2.weight: lr=1.1764899999999996e-05
paramwise_options --                                     backbone.blocks.6.norm2.bias: weight_decay=0.0
paramwise_options --                                     backbone.blocks.6.norm2.bias: weight_decay=0.0
paramwise_options --                                     backbone.blocks.6.norm2.bias: lr=1.1764899999999996e-05
paramwise_options --                                     backbone.blocks.6.mlp.fc1.weight: lr=1.1764899999999996e-05
paramwise_options --                                     backbone.blocks.6.mlp.fc1.bias: weight_decay=0.0
paramwise_options --                                     backbone.blocks.6.mlp.fc1.bias: lr=1.1764899999999996e-05
paramwise_options --                                     backbone.blocks.6.mlp.fc2.weight: lr=1.1764899999999996e-05
paramwise_options --                                     backbone.blocks.6.mlp.fc2.bias: weight_decay=0.0
paramwise_options --                                     backbone.blocks.6.mlp.fc2.bias: lr=1.1764899999999996e-05
paramwise_options --                                     backbone.blocks.7.norm1.weight: weight_decay=0.0
paramwise_options --                                     backbone.blocks.7.norm1.weight: lr=1.6806999999999993e-05
paramwise_options --                                     backbone.blocks.7.norm1.bias: weight_decay=0.0
paramwise_options --                                     backbone.blocks.7.norm1.bias: weight_decay=0.0
paramwise_options --                                     backbone.blocks.7.norm1.bias: lr=1.6806999999999993e-05
paramwise_options --                                     backbone.blocks.7.attn.qkv.weight: lr=1.6806999999999993e-05
paramwise_options --                                     backbone.blocks.7.attn.qkv.bias: weight_decay=0.0
paramwise_options --                                     backbone.blocks.7.attn.qkv.bias: lr=1.6806999999999993e-05
paramwise_options --                                     backbone.blocks.7.attn.proj.weight: lr=1.6806999999999993e-05
paramwise_options --                                     backbone.blocks.7.attn.proj.bias: weight_decay=0.0
paramwise_options --                                     backbone.blocks.7.attn.proj.bias: lr=1.6806999999999993e-05
paramwise_options --                                     backbone.blocks.7.norm2.weight: weight_decay=0.0
paramwise_options --                                     backbone.blocks.7.norm2.weight: lr=1.6806999999999993e-05
paramwise_options --                                     backbone.blocks.7.norm2.bias: weight_decay=0.0
paramwise_options --                                     backbone.blocks.7.norm2.bias: weight_decay=0.0
paramwise_options --                                     backbone.blocks.7.norm2.bias: lr=1.6806999999999993e-05
paramwise_options --                                     backbone.blocks.7.mlp.fc1.weight: lr=1.6806999999999993e-05
paramwise_options --                                     backbone.blocks.7.mlp.fc1.bias: weight_decay=0.0
paramwise_options --                                     backbone.blocks.7.mlp.fc1.bias: lr=1.6806999999999993e-05
paramwise_options --                                     backbone.blocks.7.mlp.fc2.weight: lr=1.6806999999999993e-05
paramwise_options --                                     backbone.blocks.7.mlp.fc2.bias: weight_decay=0.0
paramwise_options --                                     backbone.blocks.7.mlp.fc2.bias: lr=1.6806999999999993e-05
paramwise_options --                                     backbone.blocks.8.norm1.weight: weight_decay=0.0
paramwise_options --                                     backbone.blocks.8.norm1.weight: lr=2.4009999999999995e-05
paramwise_options --                                     backbone.blocks.8.norm1.bias: weight_decay=0.0
paramwise_options --                                     backbone.blocks.8.norm1.bias: weight_decay=0.0
paramwise_options --                                     backbone.blocks.8.norm1.bias: lr=2.4009999999999995e-05
paramwise_options --                                     backbone.blocks.8.attn.qkv.weight: lr=2.4009999999999995e-05
paramwise_options --                                     backbone.blocks.8.attn.qkv.bias: weight_decay=0.0
paramwise_options --                                     backbone.blocks.8.attn.qkv.bias: lr=2.4009999999999995e-05
paramwise_options --                                     backbone.blocks.8.attn.proj.weight: lr=2.4009999999999995e-05
paramwise_options --                                     backbone.blocks.8.attn.proj.bias: weight_decay=0.0
paramwise_options --                                     backbone.blocks.8.attn.proj.bias: lr=2.4009999999999995e-05
paramwise_options --                                     backbone.blocks.8.norm2.weight: weight_decay=0.0
paramwise_options --                                     backbone.blocks.8.norm2.weight: lr=2.4009999999999995e-05
paramwise_options --                                     backbone.blocks.8.norm2.bias: weight_decay=0.0
paramwise_options --                                     backbone.blocks.8.norm2.bias: weight_decay=0.0
paramwise_options --                                     backbone.blocks.8.norm2.bias: lr=2.4009999999999995e-05
paramwise_options --                                     backbone.blocks.8.mlp.fc1.weight: lr=2.4009999999999995e-05
paramwise_options --                                     backbone.blocks.8.mlp.fc1.bias: weight_decay=0.0
paramwise_options --                                     backbone.blocks.8.mlp.fc1.bias: lr=2.4009999999999995e-05
paramwise_options --                                     backbone.blocks.8.mlp.fc2.weight: lr=2.4009999999999995e-05
paramwise_options --                                     backbone.blocks.8.mlp.fc2.bias: weight_decay=0.0
paramwise_options --                                     backbone.blocks.8.mlp.fc2.bias: lr=2.4009999999999995e-05
paramwise_options --                                     backbone.blocks.9.norm1.weight: weight_decay=0.0
paramwise_options --                                     backbone.blocks.9.norm1.weight: lr=3.4299999999999993e-05
paramwise_options --                                     backbone.blocks.9.norm1.bias: weight_decay=0.0
paramwise_options --                                     backbone.blocks.9.norm1.bias: weight_decay=0.0
paramwise_options --                                     backbone.blocks.9.norm1.bias: lr=3.4299999999999993e-05
paramwise_options --                                     backbone.blocks.9.attn.qkv.weight: lr=3.4299999999999993e-05
paramwise_options --                                     backbone.blocks.9.attn.qkv.bias: weight_decay=0.0
paramwise_options --                                     backbone.blocks.9.attn.qkv.bias: lr=3.4299999999999993e-05
paramwise_options --                                     backbone.blocks.9.attn.proj.weight: lr=3.4299999999999993e-05
paramwise_options --                                     backbone.blocks.9.attn.proj.bias: weight_decay=0.0
paramwise_options --                                     backbone.blocks.9.attn.proj.bias: lr=3.4299999999999993e-05
paramwise_options --                                     backbone.blocks.9.norm2.weight: weight_decay=0.0
paramwise_options --                                     backbone.blocks.9.norm2.weight: lr=3.4299999999999993e-05
paramwise_options --                                     backbone.blocks.9.norm2.bias: weight_decay=0.0
paramwise_options --                                     backbone.blocks.9.norm2.bias: weight_decay=0.0
paramwise_options --                                     backbone.blocks.9.norm2.bias: lr=3.4299999999999993e-05
paramwise_options --                                     backbone.blocks.9.mlp.fc1.weight: lr=3.4299999999999993e-05
paramwise_options --                                     backbone.blocks.9.mlp.fc1.bias: weight_decay=0.0
paramwise_options --                                     backbone.blocks.9.mlp.fc1.bias: lr=3.4299999999999993e-05
paramwise_options --                                     backbone.blocks.9.mlp.fc2.weight: lr=3.4299999999999993e-05
paramwise_options --                                     backbone.blocks.9.mlp.fc2.bias: weight_decay=0.0
paramwise_options --                                     backbone.blocks.9.mlp.fc2.bias: lr=3.4299999999999993e-05
paramwise_options --                                     backbone.blocks.10.norm1.weight: weight_decay=0.0
paramwise_options --                                     backbone.blocks.10.norm1.weight: lr=4.9e-05
paramwise_options --                                     backbone.blocks.10.norm1.bias: weight_decay=0.0
paramwise_options --                                     backbone.blocks.10.norm1.bias: weight_decay=0.0
paramwise_options --                                     backbone.blocks.10.norm1.bias: lr=4.9e-05
paramwise_options --                                     backbone.blocks.10.attn.qkv.weight: lr=4.9e-05
paramwise_options --                                     backbone.blocks.10.attn.qkv.bias: weight_decay=0.0
paramwise_options --                                     backbone.blocks.10.attn.qkv.bias: lr=4.9e-05
paramwise_options --                                     backbone.blocks.10.attn.proj.weight: lr=4.9e-05
paramwise_options --                                     backbone.blocks.10.attn.proj.bias: weight_decay=0.0
paramwise_options --                                     backbone.blocks.10.attn.proj.bias: lr=4.9e-05
paramwise_options --                                     backbone.blocks.10.norm2.weight: weight_decay=0.0
paramwise_options --                                     backbone.blocks.10.norm2.weight: lr=4.9e-05
paramwise_options --                                     backbone.blocks.10.norm2.bias: weight_decay=0.0
paramwise_options --                                     backbone.blocks.10.norm2.bias: weight_decay=0.0
paramwise_options --                                     backbone.blocks.10.norm2.bias: lr=4.9e-05
paramwise_options --                                     backbone.blocks.10.mlp.fc1.weight: lr=4.9e-05
paramwise_options --                                     backbone.blocks.10.mlp.fc1.bias: weight_decay=0.0
paramwise_options --                                     backbone.blocks.10.mlp.fc1.bias: lr=4.9e-05
paramwise_options --                                     backbone.blocks.10.mlp.fc2.weight: lr=4.9e-05
paramwise_options --                                     backbone.blocks.10.mlp.fc2.bias: weight_decay=0.0
paramwise_options --                                     backbone.blocks.10.mlp.fc2.bias: lr=4.9e-05
paramwise_options --                                     backbone.blocks.11.norm1.weight: weight_decay=0.0
paramwise_options --                                     backbone.blocks.11.norm1.weight: lr=7e-05
paramwise_options --                                     backbone.blocks.11.norm1.bias: weight_decay=0.0
paramwise_options --                                     backbone.blocks.11.norm1.bias: weight_decay=0.0
paramwise_options --                                     backbone.blocks.11.norm1.bias: lr=7e-05
paramwise_options --                                     backbone.blocks.11.attn.qkv.weight: lr=7e-05
paramwise_options --                                     backbone.blocks.11.attn.qkv.bias: weight_decay=0.0
paramwise_options --                                     backbone.blocks.11.attn.qkv.bias: lr=7e-05
paramwise_options --                                     backbone.blocks.11.attn.proj.weight: lr=7e-05
paramwise_options --                                     backbone.blocks.11.attn.proj.bias: weight_decay=0.0
paramwise_options --                                     backbone.blocks.11.attn.proj.bias: lr=7e-05
paramwise_options --                                     backbone.blocks.11.norm2.weight: weight_decay=0.0
paramwise_options --                                     backbone.blocks.11.norm2.weight: lr=7e-05
paramwise_options --                                     backbone.blocks.11.norm2.bias: weight_decay=0.0
paramwise_options --                                     backbone.blocks.11.norm2.bias: weight_decay=0.0
paramwise_options --                                     backbone.blocks.11.norm2.bias: lr=7e-05
paramwise_options --                                     backbone.blocks.11.mlp.fc1.weight: lr=7e-05
paramwise_options --                                     backbone.blocks.11.mlp.fc1.bias: weight_decay=0.0
paramwise_options --                                     backbone.blocks.11.mlp.fc1.bias: lr=7e-05
paramwise_options --                                     backbone.blocks.11.mlp.fc2.weight: lr=7e-05
paramwise_options --                                     backbone.blocks.11.mlp.fc2.bias: weight_decay=0.0
paramwise_options --                                     backbone.blocks.11.mlp.fc2.bias: lr=7e-05
paramwise_options --                                     backbone.norm.weight: weight_decay=0.0
paramwise_options --                                     backbone.norm.bias: weight_decay=0.0
paramwise_options --                                     backbone.norm.bias: weight_decay=0.0
paramwise_options --                                     neck.top_downs.0.0.bias: weight_decay=0.0
paramwise_options --                                     neck.top_downs.0.1.bias: weight_decay=0.0
paramwise_options --                                     neck.top_downs.0.3.bias: weight_decay=0.0
paramwise_options --                                     neck.top_downs.1.bias: weight_decay=0.0
paramwise_options --                                     neck.sfp_outs.0.0.bias: weight_decay=0.0
paramwise_options --                                     neck.sfp_outs.0.1.bias: weight_decay=0.0
paramwise_options --                                     neck.sfp_outs.0.2.bias: weight_decay=0.0
paramwise_options --                                     neck.sfp_outs.0.3.bias: weight_decay=0.0
paramwise_options --                                     neck.sfp_outs.1.0.bias: weight_decay=0.0
paramwise_options --                                     neck.sfp_outs.1.1.bias: weight_decay=0.0
paramwise_options --                                     neck.sfp_outs.1.2.bias: weight_decay=0.0
paramwise_options --                                     neck.sfp_outs.1.3.bias: weight_decay=0.0
paramwise_options --                                     neck.sfp_outs.2.0.bias: weight_decay=0.0
paramwise_options --                                     neck.sfp_outs.2.1.bias: weight_decay=0.0
paramwise_options --                                     neck.sfp_outs.2.2.bias: weight_decay=0.0
paramwise_options --                                     neck.sfp_outs.2.3.bias: weight_decay=0.0
paramwise_options --                                     neck.sfp_outs.3.0.bias: weight_decay=0.0
paramwise_options --                                     neck.sfp_outs.3.1.bias: weight_decay=0.0
paramwise_options --                                     neck.sfp_outs.3.2.bias: weight_decay=0.0
paramwise_options --                                     neck.sfp_outs.3.3.bias: weight_decay=0.0
paramwise_options --                                     rpn_head.rpn_conv.0.conv.bias: weight_decay=0.0
paramwise_options --                                     rpn_head.rpn_conv.1.conv.bias: weight_decay=0.0
paramwise_options --                                     rpn_head.rpn_cls.bias: weight_decay=0.0
paramwise_options --                                     rpn_head.rpn_reg.bias: weight_decay=0.0
paramwise_options --                                     roi_head.bbox_head.fc_cls.bias: weight_decay=0.0
paramwise_options --                                     roi_head.bbox_head.fc_reg.bias: weight_decay=0.0
paramwise_options --                                     roi_head.bbox_head.shared_convs.0.bn.bias: weight_decay=0.0
paramwise_options --                                     roi_head.bbox_head.shared_convs.1.bn.bias: weight_decay=0.0
paramwise_options --                                     roi_head.bbox_head.shared_convs.2.bn.bias: weight_decay=0.0
paramwise_options --                                     roi_head.bbox_head.shared_convs.3.bn.bias: weight_decay=0.0
paramwise_options --                                     roi_head.bbox_head.shared_fcs.0.bias: weight_decay=0.0
paramwise_options --                                     roi_head.mask_head.convs.0.bn.bias: weight_decay=0.0
paramwise_options --                                     roi_head.mask_head.convs.1.bn.bias: weight_decay=0.0
paramwise_options --                                     roi_head.mask_head.convs.2.bn.bias: weight_decay=0.0
paramwise_options --                                     roi_head.mask_head.convs.3.bn.bias: weight_decay=0.0
paramwise_options --                                     roi_head.mask_head.upsample.bias: weight_decay=0.0
paramwise_options --                                     roi_head.mask_head.conv_logits.bias: weight_decay=0.0
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
Done (t=0.52s)
creating index...
Done (t=0.52s)
creating index...
Done (t=0.53s)
creating index...
Done (t=0.52s)
creating index...
Done (t=0.52s)
creating index...
Done (t=0.53s)
creating index...
Done (t=0.53s)
creating index...
Done (t=0.53s)
creating index...
index created!
index created!
index created!
index created!
index created!
index created!
index created!
index created!
2022-04-15 11:33:59,954 - mmdet - INFO - Start running, host: yunji.cjy@j38g08156.eu95sqa, work_dir: /home/yunji.cjy/codebase/mmdetection/work_dirs/vitdet_sfp_100e_fp16_coco
2022-04-15 11:33:59,954 - mmdet - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) StepLrUpdaterHook                  
(ABOVE_NORMAL) GradientCumulativeFp16OptimizerHook
(NORMAL      ) CheckpointHook                     
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) NumClassCheckHook                  
(NORMAL      ) DistSamplerSeedHook                
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) StepLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) GradientCumulativeFp16OptimizerHook
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(NORMAL      ) NumClassCheckHook                  
(NORMAL      ) DistSamplerSeedHook                
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
2022-04-15 11:33:59,954 - mmdet - INFO - workflow: [('train', 1)], max: 25 epochs
2022-04-15 11:33:59,956 - mmdet - INFO - Checkpoints will be saved to /home/yunji.cjy/codebase/mmdetection/work_dirs/vitdet_sfp_100e_fp16_coco by HardDiskBackend.
2022-04-15 11:34:34,787 - mmdet - INFO - Epoch [1][50/29317]	lr: 4.840e-08, eta: 5 days, 21:47:34, time: 0.697, data_time: 0.238, memory: 10533, loss_rpn_cls: 0.6935, loss_rpn_bbox: 0.0919, loss_cls: 4.1790, acc: 12.2619, loss_bbox: 0.0293, loss_mask: 0.7728, loss: 5.7665
2022-04-15 11:34:58,468 - mmdet - INFO - Epoch [1][100/29317]	lr: 9.679e-08, eta: 4 days, 23:05:44, time: 0.474, data_time: 0.034, memory: 10718, loss_rpn_cls: 0.6847, loss_rpn_bbox: 0.0839, loss_cls: 2.7840, acc: 96.5606, loss_bbox: 0.0321, loss_mask: 0.7648, loss: 4.3494
2022-04-15 11:35:22,306 - mmdet - INFO - Epoch [1][150/29317]	lr: 1.452e-07, eta: 4 days, 15:44:23, time: 0.477, data_time: 0.040, memory: 10718, loss_rpn_cls: 0.6645, loss_rpn_bbox: 0.0909, loss_cls: 0.8136, acc: 97.5933, loss_bbox: 0.0489, loss_mask: 0.7505, loss: 2.3683
2022-04-15 11:35:46,544 - mmdet - INFO - Epoch [1][200/29317]	lr: 1.936e-07, eta: 4 days, 12:27:49, time: 0.485, data_time: 0.036, memory: 10729, loss_rpn_cls: 0.6086, loss_rpn_bbox: 0.0915, loss_cls: 0.2690, acc: 97.0962, loss_bbox: 0.0701, loss_mask: 0.7370, loss: 1.7761
2022-04-15 11:36:10,872 - mmdet - INFO - Epoch [1][250/29317]	lr: 2.420e-07, eta: 4 days, 10:34:12, time: 0.487, data_time: 0.036, memory: 10729, loss_rpn_cls: 0.4512, loss_rpn_bbox: 0.0912, loss_cls: 0.3068, acc: 96.7301, loss_bbox: 0.0871, loss_mask: 0.7189, loss: 1.6553
2022-04-15 11:36:35,099 - mmdet - INFO - Epoch [1][300/29317]	lr: 2.904e-07, eta: 4 days, 9:14:11, time: 0.485, data_time: 0.033, memory: 10903, loss_rpn_cls: 0.2689, loss_rpn_bbox: 0.0847, loss_cls: 0.3476, acc: 95.9938, loss_bbox: 0.1226, loss_mask: 0.7119, loss: 1.5357
2022-04-15 11:36:59,333 - mmdet - INFO - Epoch [1][350/29317]	lr: 3.388e-07, eta: 4 days, 8:17:09, time: 0.485, data_time: 0.044, memory: 10903, loss_rpn_cls: 0.2471, loss_rpn_bbox: 0.0880, loss_cls: 0.3473, acc: 95.4249, loss_bbox: 0.1434, loss_mask: 0.6960, loss: 1.5219
2022-04-15 11:37:23,346 - mmdet - INFO - Epoch [1][400/29317]	lr: 3.872e-07, eta: 4 days, 7:27:27, time: 0.480, data_time: 0.034, memory: 10903, loss_rpn_cls: 0.1999, loss_rpn_bbox: 0.0782, loss_cls: 0.3312, acc: 95.4924, loss_bbox: 0.1470, loss_mask: 0.6852, loss: 1.4415
2022-04-15 11:37:47,493 - mmdet - INFO - Epoch [1][450/29317]	lr: 4.356e-07, eta: 4 days, 6:52:29, time: 0.483, data_time: 0.042, memory: 10903, loss_rpn_cls: 0.1991, loss_rpn_bbox: 0.0829, loss_cls: 0.3500, acc: 95.0906, loss_bbox: 0.1616, loss_mask: 0.6693, loss: 1.4630
2022-04-15 11:38:11,348 - mmdet - INFO - Epoch [1][500/29317]	lr: 4.840e-07, eta: 4 days, 6:17:13, time: 0.477, data_time: 0.034, memory: 10903, loss_rpn_cls: 0.1743, loss_rpn_bbox: 0.0799, loss_cls: 0.3609, acc: 94.8943, loss_bbox: 0.1750, loss_mask: 0.6614, loss: 1.4515
2022-04-15 11:38:36,458 - mmdet - INFO - Epoch [1][550/29317]	lr: 5.324e-07, eta: 4 days, 6:16:12, time: 0.502, data_time: 0.036, memory: 10949, loss_rpn_cls: 0.1693, loss_rpn_bbox: 0.0863, loss_cls: 0.3750, acc: 94.5442, loss_bbox: 0.1835, loss_mask: 0.6494, loss: 1.4635
2022-04-15 11:39:00,496 - mmdet - INFO - Epoch [1][600/29317]	lr: 5.808e-07, eta: 4 days, 5:53:25, time: 0.481, data_time: 0.038, memory: 10954, loss_rpn_cls: 0.1513, loss_rpn_bbox: 0.0804, loss_cls: 0.3524, acc: 94.9199, loss_bbox: 0.1719, loss_mask: 0.6405, loss: 1.3965
2022-04-15 11:39:25,003 - mmdet - INFO - Epoch [1][650/29317]	lr: 6.291e-07, eta: 4 days, 5:42:55, time: 0.490, data_time: 0.042, memory: 11014, loss_rpn_cls: 0.1377, loss_rpn_bbox: 0.0839, loss_cls: 0.3695, acc: 94.5549, loss_bbox: 0.1841, loss_mask: 0.6276, loss: 1.4029
2022-04-15 11:39:48,956 - mmdet - INFO - Epoch [1][700/29317]	lr: 6.775e-07, eta: 4 days, 5:24:10, time: 0.479, data_time: 0.035, memory: 11014, loss_rpn_cls: 0.1402, loss_rpn_bbox: 0.0868, loss_cls: 0.3598, acc: 94.6880, loss_bbox: 0.1797, loss_mask: 0.6163, loss: 1.3827
2022-04-15 11:40:12,798 - mmdet - INFO - Epoch [1][750/29317]	lr: 7.259e-07, eta: 4 days, 5:06:07, time: 0.477, data_time: 0.039, memory: 11014, loss_rpn_cls: 0.1185, loss_rpn_bbox: 0.0779, loss_cls: 0.3661, acc: 94.5798, loss_bbox: 0.1872, loss_mask: 0.6065, loss: 1.3562
2022-04-15 11:40:36,942 - mmdet - INFO - Epoch [1][800/29317]	lr: 7.743e-07, eta: 4 days, 4:54:49, time: 0.483, data_time: 0.032, memory: 11014, loss_rpn_cls: 0.1248, loss_rpn_bbox: 0.0844, loss_cls: 0.3863, acc: 94.2925, loss_bbox: 0.1962, loss_mask: 0.6003, loss: 1.3920
2022-04-15 11:41:00,573 - mmdet - INFO - Epoch [1][850/29317]	lr: 8.227e-07, eta: 4 days, 4:37:30, time: 0.473, data_time: 0.043, memory: 11014, loss_rpn_cls: 0.1163, loss_rpn_bbox: 0.0787, loss_cls: 0.3725, acc: 94.4502, loss_bbox: 0.1908, loss_mask: 0.5886, loss: 1.3469
2022-04-15 11:41:24,134 - mmdet - INFO - Epoch [1][900/29317]	lr: 8.711e-07, eta: 4 days, 4:21:04, time: 0.471, data_time: 0.034, memory: 11014, loss_rpn_cls: 0.1148, loss_rpn_bbox: 0.0801, loss_cls: 0.3826, acc: 94.1729, loss_bbox: 0.2041, loss_mask: 0.5831, loss: 1.3646
2022-04-15 11:41:48,147 - mmdet - INFO - Epoch [1][950/29317]	lr: 9.195e-07, eta: 4 days, 4:12:09, time: 0.480, data_time: 0.037, memory: 11014, loss_rpn_cls: 0.1088, loss_rpn_bbox: 0.0786, loss_cls: 0.3699, acc: 94.3789, loss_bbox: 0.1937, loss_mask: 0.5810, loss: 1.3319
2022-04-15 11:42:12,033 - mmdet - INFO - Exp name: vitdet_sfp_100e_fp16_coco.py
2022-04-15 11:42:12,033 - mmdet - INFO - Epoch [1][1000/29317]	lr: 9.679e-07, eta: 4 days, 4:02:30, time: 0.478, data_time: 0.032, memory: 11014, loss_rpn_cls: 0.1008, loss_rpn_bbox: 0.0768, loss_cls: 0.3687, acc: 94.3928, loss_bbox: 0.1948, loss_mask: 0.5659, loss: 1.3070
2022-04-15 11:42:36,122 - mmdet - INFO - Epoch [1][1050/29317]	lr: 9.689e-07, eta: 4 days, 3:56:07, time: 0.482, data_time: 0.034, memory: 11081, loss_rpn_cls: 0.0949, loss_rpn_bbox: 0.0709, loss_cls: 0.3752, acc: 94.2806, loss_bbox: 0.2003, loss_mask: 0.5564, loss: 1.2977
2022-04-15 11:43:00,158 - mmdet - INFO - Epoch [1][1100/29317]	lr: 9.689e-07, eta: 4 days, 3:49:29, time: 0.480, data_time: 0.036, memory: 11081, loss_rpn_cls: 0.1054, loss_rpn_bbox: 0.0845, loss_cls: 0.3908, acc: 93.7522, loss_bbox: 0.2194, loss_mask: 0.5484, loss: 1.3484
2022-04-15 11:43:25,035 - mmdet - INFO - Epoch [1][1150/29317]	lr: 9.689e-07, eta: 4 days, 3:52:42, time: 0.498, data_time: 0.038, memory: 11081, loss_rpn_cls: 0.1007, loss_rpn_bbox: 0.0822, loss_cls: 0.4113, acc: 93.4751, loss_bbox: 0.2293, loss_mask: 0.5509, loss: 1.3743
2022-04-15 11:43:49,301 - mmdet - INFO - Epoch [1][1200/29317]	lr: 9.689e-07, eta: 4 days, 3:49:12, time: 0.485, data_time: 0.038, memory: 11081, loss_rpn_cls: 0.0980, loss_rpn_bbox: 0.0787, loss_cls: 0.4112, acc: 93.3857, loss_bbox: 0.2350, loss_mask: 0.5345, loss: 1.3575
2022-04-15 11:44:13,266 - mmdet - INFO - Epoch [1][1250/29317]	lr: 9.689e-07, eta: 4 days, 3:43:03, time: 0.479, data_time: 0.034, memory: 11085, loss_rpn_cls: 0.0923, loss_rpn_bbox: 0.0750, loss_cls: 0.3978, acc: 93.4341, loss_bbox: 0.2322, loss_mask: 0.5295, loss: 1.3269
2022-04-15 11:44:37,477 - mmdet - INFO - Epoch [1][1300/29317]	lr: 9.689e-07, eta: 4 days, 3:39:37, time: 0.484, data_time: 0.035, memory: 11085, loss_rpn_cls: 0.0869, loss_rpn_bbox: 0.0730, loss_cls: 0.4094, acc: 93.2061, loss_bbox: 0.2406, loss_mask: 0.5196, loss: 1.3294
2022-04-15 11:45:01,832 - mmdet - INFO - Epoch [1][1350/29317]	lr: 9.689e-07, eta: 4 days, 3:37:44, time: 0.487, data_time: 0.042, memory: 11085, loss_rpn_cls: 0.0942, loss_rpn_bbox: 0.0797, loss_cls: 0.4310, acc: 92.6035, loss_bbox: 0.2593, loss_mask: 0.5160, loss: 1.3802
2022-04-15 11:45:25,889 - mmdet - INFO - Epoch [1][1400/29317]	lr: 9.689e-07, eta: 4 days, 3:33:20, time: 0.481, data_time: 0.034, memory: 11090, loss_rpn_cls: 0.0879, loss_rpn_bbox: 0.0770, loss_cls: 0.4225, acc: 92.6418, loss_bbox: 0.2604, loss_mask: 0.5014, loss: 1.3491
2022-04-15 11:45:49,893 - mmdet - INFO - Epoch [1][1450/29317]	lr: 9.689e-07, eta: 4 days, 3:28:47, time: 0.480, data_time: 0.039, memory: 11090, loss_rpn_cls: 0.0829, loss_rpn_bbox: 0.0733, loss_cls: 0.4177, acc: 92.8691, loss_bbox: 0.2541, loss_mask: 0.5014, loss: 1.3294
2022-04-15 11:46:13,995 - mmdet - INFO - Epoch [1][1500/29317]	lr: 9.689e-07, eta: 4 days, 3:25:18, time: 0.482, data_time: 0.031, memory: 11090, loss_rpn_cls: 0.0799, loss_rpn_bbox: 0.0678, loss_cls: 0.4095, acc: 92.9165, loss_bbox: 0.2495, loss_mask: 0.4948, loss: 1.3015
2022-04-15 11:46:38,359 - mmdet - INFO - Epoch [1][1550/29317]	lr: 9.689e-07, eta: 4 days, 3:24:05, time: 0.487, data_time: 0.037, memory: 11090, loss_rpn_cls: 0.0795, loss_rpn_bbox: 0.0728, loss_cls: 0.4241, acc: 92.5606, loss_bbox: 0.2613, loss_mask: 0.4941, loss: 1.3318
2022-04-15 11:47:02,687 - mmdet - INFO - Epoch [1][1600/29317]	lr: 9.689e-07, eta: 4 days, 3:22:37, time: 0.487, data_time: 0.041, memory: 11090, loss_rpn_cls: 0.0770, loss_rpn_bbox: 0.0712, loss_cls: 0.4141, acc: 92.5747, loss_bbox: 0.2606, loss_mask: 0.4810, loss: 1.3040
2022-04-15 11:47:27,011 - mmdet - INFO - Epoch [1][1650/29317]	lr: 9.689e-07, eta: 4 days, 3:21:13, time: 0.487, data_time: 0.036, memory: 11090, loss_rpn_cls: 0.0778, loss_rpn_bbox: 0.0720, loss_cls: 0.4151, acc: 92.4050, loss_bbox: 0.2636, loss_mask: 0.4872, loss: 1.3157
2022-04-15 11:47:51,357 - mmdet - INFO - Epoch [1][1700/29317]	lr: 9.689e-07, eta: 4 days, 3:20:01, time: 0.487, data_time: 0.038, memory: 11090, loss_rpn_cls: 0.0785, loss_rpn_bbox: 0.0748, loss_cls: 0.4176, acc: 92.3320, loss_bbox: 0.2638, loss_mask: 0.4795, loss: 1.3143
2022-04-15 11:48:15,264 - mmdet - INFO - Epoch [1][1750/29317]	lr: 9.689e-07, eta: 4 days, 3:15:49, time: 0.478, data_time: 0.037, memory: 11090, loss_rpn_cls: 0.0769, loss_rpn_bbox: 0.0692, loss_cls: 0.4283, acc: 92.1846, loss_bbox: 0.2736, loss_mask: 0.4813, loss: 1.3294
2022-04-15 11:48:39,278 - mmdet - INFO - Epoch [1][1800/29317]	lr: 9.689e-07, eta: 4 days, 3:12:33, time: 0.480, data_time: 0.035, memory: 11090, loss_rpn_cls: 0.0770, loss_rpn_bbox: 0.0726, loss_cls: 0.4013, acc: 92.6655, loss_bbox: 0.2519, loss_mask: 0.4694, loss: 1.2722
2022-04-15 11:49:03,032 - mmdet - INFO - Epoch [1][1850/29317]	lr: 9.689e-07, eta: 4 days, 3:07:43, time: 0.475, data_time: 0.032, memory: 11090, loss_rpn_cls: 0.0735, loss_rpn_bbox: 0.0697, loss_cls: 0.4141, acc: 92.2839, loss_bbox: 0.2670, loss_mask: 0.4705, loss: 1.2948
2022-04-15 11:49:26,712 - mmdet - INFO - Epoch [1][1900/29317]	lr: 9.689e-07, eta: 4 days, 3:02:39, time: 0.474, data_time: 0.036, memory: 11090, loss_rpn_cls: 0.0768, loss_rpn_bbox: 0.0696, loss_cls: 0.4004, acc: 92.5303, loss_bbox: 0.2563, loss_mask: 0.4653, loss: 1.2683
2022-04-15 11:49:51,550 - mmdet - INFO - Epoch [1][1950/29317]	lr: 9.689e-07, eta: 4 days, 3:05:03, time: 0.497, data_time: 0.039, memory: 11094, loss_rpn_cls: 0.0787, loss_rpn_bbox: 0.0709, loss_cls: 0.4067, acc: 92.3506, loss_bbox: 0.2618, loss_mask: 0.4736, loss: 1.2918
2022-04-15 11:50:15,843 - mmdet - INFO - Exp name: vitdet_sfp_100e_fp16_coco.py
2022-04-15 11:50:15,844 - mmdet - INFO - Epoch [1][2000/29317]	lr: 9.689e-07, eta: 4 days, 3:03:59, time: 0.486, data_time: 0.035, memory: 11094, loss_rpn_cls: 0.0735, loss_rpn_bbox: 0.0674, loss_cls: 0.4040, acc: 92.2361, loss_bbox: 0.2659, loss_mask: 0.4535, loss: 1.2643
2022-04-15 11:50:40,103 - mmdet - INFO - Epoch [1][2050/29317]	lr: 9.689e-07, eta: 4 days, 3:02:46, time: 0.485, data_time: 0.036, memory: 11094, loss_rpn_cls: 0.0777, loss_rpn_bbox: 0.0719, loss_cls: 0.4127, acc: 91.9807, loss_bbox: 0.2770, loss_mask: 0.4555, loss: 1.2948
2022-04-15 11:51:03,868 - mmdet - INFO - Epoch [1][2100/29317]	lr: 9.689e-07, eta: 4 days, 2:58:42, time: 0.475, data_time: 0.035, memory: 11094, loss_rpn_cls: 0.0697, loss_rpn_bbox: 0.0643, loss_cls: 0.3922, acc: 92.4048, loss_bbox: 0.2585, loss_mask: 0.4427, loss: 1.2276
2022-04-15 11:51:28,146 - mmdet - INFO - Epoch [1][2150/29317]	lr: 9.689e-07, eta: 4 days, 2:57:45, time: 0.486, data_time: 0.042, memory: 11094, loss_rpn_cls: 0.0701, loss_rpn_bbox: 0.0683, loss_cls: 0.4063, acc: 91.9722, loss_bbox: 0.2767, loss_mask: 0.4411, loss: 1.2626
2022-04-15 11:51:52,293 - mmdet - INFO - Epoch [1][2200/29317]	lr: 9.689e-07, eta: 4 days, 2:55:58, time: 0.483, data_time: 0.040, memory: 11094, loss_rpn_cls: 0.0720, loss_rpn_bbox: 0.0643, loss_cls: 0.4021, acc: 92.0515, loss_bbox: 0.2706, loss_mask: 0.4352, loss: 1.2442
2022-04-15 11:52:16,960 - mmdet - INFO - Epoch [1][2250/29317]	lr: 9.689e-07, eta: 4 days, 2:57:16, time: 0.494, data_time: 0.035, memory: 11094, loss_rpn_cls: 0.0704, loss_rpn_bbox: 0.0679, loss_cls: 0.3921, acc: 92.2064, loss_bbox: 0.2645, loss_mask: 0.4433, loss: 1.2382
2022-04-15 11:52:41,027 - mmdet - INFO - Epoch [1][2300/29317]	lr: 9.689e-07, eta: 4 days, 2:55:12, time: 0.481, data_time: 0.031, memory: 11094, loss_rpn_cls: 0.0683, loss_rpn_bbox: 0.0662, loss_cls: 0.3944, acc: 91.9712, loss_bbox: 0.2716, loss_mask: 0.4401, loss: 1.2406
2022-04-15 11:53:05,624 - mmdet - INFO - Epoch [1][2350/29317]	lr: 9.689e-07, eta: 4 days, 2:55:58, time: 0.492, data_time: 0.044, memory: 11094, loss_rpn_cls: 0.0723, loss_rpn_bbox: 0.0684, loss_cls: 0.4007, acc: 91.7363, loss_bbox: 0.2787, loss_mask: 0.4416, loss: 1.2617
2022-04-15 11:53:29,817 - mmdet - INFO - Epoch [1][2400/29317]	lr: 9.689e-07, eta: 4 days, 2:54:38, time: 0.484, data_time: 0.038, memory: 11094, loss_rpn_cls: 0.0670, loss_rpn_bbox: 0.0668, loss_cls: 0.3871, acc: 91.9788, loss_bbox: 0.2739, loss_mask: 0.4376, loss: 1.2323
2022-04-15 11:53:54,501 - mmdet - INFO - Epoch [1][2450/29317]	lr: 9.689e-07, eta: 4 days, 2:55:47, time: 0.494, data_time: 0.037, memory: 11094, loss_rpn_cls: 0.0722, loss_rpn_bbox: 0.0679, loss_cls: 0.3816, acc: 91.9553, loss_bbox: 0.2737, loss_mask: 0.4272, loss: 1.2226
2022-04-15 11:54:18,692 - mmdet - INFO - Epoch [1][2500/29317]	lr: 9.689e-07, eta: 4 days, 2:54:28, time: 0.484, data_time: 0.033, memory: 11094, loss_rpn_cls: 0.0639, loss_rpn_bbox: 0.0638, loss_cls: 0.3803, acc: 92.1562, loss_bbox: 0.2643, loss_mask: 0.4324, loss: 1.2048
2022-04-15 11:54:42,848 - mmdet - INFO - Epoch [1][2550/29317]	lr: 9.689e-07, eta: 4 days, 2:53:01, time: 0.483, data_time: 0.034, memory: 11094, loss_rpn_cls: 0.0701, loss_rpn_bbox: 0.0678, loss_cls: 0.3890, acc: 91.8315, loss_bbox: 0.2686, loss_mask: 0.4293, loss: 1.2247
2022-04-15 11:55:07,352 - mmdet - INFO - Epoch [1][2600/29317]	lr: 9.689e-07, eta: 4 days, 2:53:14, time: 0.490, data_time: 0.040, memory: 11094, loss_rpn_cls: 0.0665, loss_rpn_bbox: 0.0655, loss_cls: 0.3918, acc: 91.5703, loss_bbox: 0.2770, loss_mask: 0.4227, loss: 1.2234
2022-04-15 11:55:31,003 - mmdet - INFO - Epoch [1][2650/29317]	lr: 9.689e-07, eta: 4 days, 2:49:31, time: 0.473, data_time: 0.038, memory: 11094, loss_rpn_cls: 0.0625, loss_rpn_bbox: 0.0628, loss_cls: 0.3801, acc: 91.9912, loss_bbox: 0.2681, loss_mask: 0.4216, loss: 1.1952
2022-04-15 11:55:55,601 - mmdet - INFO - Epoch [1][2700/29317]	lr: 9.689e-07, eta: 4 days, 2:50:08, time: 0.492, data_time: 0.031, memory: 11094, loss_rpn_cls: 0.0718, loss_rpn_bbox: 0.0709, loss_cls: 0.3992, acc: 91.3293, loss_bbox: 0.2879, loss_mask: 0.4214, loss: 1.2511
2022-04-15 11:56:19,582 - mmdet - INFO - Epoch [1][2750/29317]	lr: 9.689e-07, eta: 4 days, 2:48:05, time: 0.480, data_time: 0.036, memory: 11094, loss_rpn_cls: 0.0657, loss_rpn_bbox: 0.0652, loss_cls: 0.3810, acc: 91.9661, loss_bbox: 0.2685, loss_mask: 0.4195, loss: 1.2000
2022-04-15 11:56:43,271 - mmdet - INFO - Epoch [1][2800/29317]	lr: 9.689e-07, eta: 4 days, 2:44:47, time: 0.474, data_time: 0.030, memory: 11094, loss_rpn_cls: 0.0646, loss_rpn_bbox: 0.0620, loss_cls: 0.3660, acc: 92.1052, loss_bbox: 0.2654, loss_mask: 0.4179, loss: 1.1758
2022-04-15 11:57:07,777 - mmdet - INFO - Epoch [1][2850/29317]	lr: 9.689e-07, eta: 4 days, 2:45:04, time: 0.490, data_time: 0.037, memory: 11094, loss_rpn_cls: 0.0632, loss_rpn_bbox: 0.0651, loss_cls: 0.3829, acc: 91.5908, loss_bbox: 0.2761, loss_mask: 0.4231, loss: 1.2105
2022-04-15 11:57:31,995 - mmdet - INFO - Epoch [1][2900/29317]	lr: 9.689e-07, eta: 4 days, 2:44:06, time: 0.484, data_time: 0.033, memory: 11094, loss_rpn_cls: 0.0629, loss_rpn_bbox: 0.0599, loss_cls: 0.3667, acc: 92.1211, loss_bbox: 0.2598, loss_mask: 0.4183, loss: 1.1674
2022-04-15 11:57:56,283 - mmdet - INFO - Epoch [1][2950/29317]	lr: 9.689e-07, eta: 4 days, 2:43:28, time: 0.486, data_time: 0.035, memory: 11094, loss_rpn_cls: 0.0660, loss_rpn_bbox: 0.0664, loss_cls: 0.3777, acc: 91.8083, loss_bbox: 0.2712, loss_mask: 0.4035, loss: 1.1848
2022-04-15 11:58:20,299 - mmdet - INFO - Exp name: vitdet_sfp_100e_fp16_coco.py
2022-04-15 11:58:20,299 - mmdet - INFO - Epoch [1][3000/29317]	lr: 9.689e-07, eta: 4 days, 2:41:43, time: 0.480, data_time: 0.038, memory: 11094, loss_rpn_cls: 0.0681, loss_rpn_bbox: 0.0630, loss_cls: 0.3628, acc: 92.0193, loss_bbox: 0.2681, loss_mask: 0.4164, loss: 1.1785
2022-04-15 11:58:45,001 - mmdet - INFO - Epoch [1][3050/29317]	lr: 9.689e-07, eta: 4 days, 2:42:46, time: 0.494, data_time: 0.039, memory: 11094, loss_rpn_cls: 0.0632, loss_rpn_bbox: 0.0662, loss_cls: 0.3692, acc: 91.7227, loss_bbox: 0.2731, loss_mask: 0.4097, loss: 1.1815
2022-04-15 11:59:09,340 - mmdet - INFO - Epoch [1][3100/29317]	lr: 9.689e-07, eta: 4 days, 2:42:17, time: 0.486, data_time: 0.035, memory: 11094, loss_rpn_cls: 0.0611, loss_rpn_bbox: 0.0643, loss_cls: 0.3852, acc: 91.3105, loss_bbox: 0.2867, loss_mask: 0.4110, loss: 1.2082
2022-04-15 11:59:33,135 - mmdet - INFO - Epoch [1][3150/29317]	lr: 9.689e-07, eta: 4 days, 2:39:49, time: 0.476, data_time: 0.037, memory: 11094, loss_rpn_cls: 0.0578, loss_rpn_bbox: 0.0619, loss_cls: 0.3593, acc: 91.9878, loss_bbox: 0.2669, loss_mask: 0.4018, loss: 1.1477
2022-04-15 11:59:57,538 - mmdet - INFO - Epoch [1][3200/29317]	lr: 9.689e-07, eta: 4 days, 2:39:40, time: 0.488, data_time: 0.035, memory: 11094, loss_rpn_cls: 0.0640, loss_rpn_bbox: 0.0693, loss_cls: 0.3690, acc: 91.6086, loss_bbox: 0.2774, loss_mask: 0.4039, loss: 1.1836
2022-04-15 12:00:21,619 - mmdet - INFO - Epoch [1][3250/29317]	lr: 9.689e-07, eta: 4 days, 2:38:18, time: 0.482, data_time: 0.034, memory: 11094, loss_rpn_cls: 0.0623, loss_rpn_bbox: 0.0617, loss_cls: 0.3615, acc: 91.8943, loss_bbox: 0.2651, loss_mask: 0.4016, loss: 1.1522
2022-04-15 12:00:45,707 - mmdet - INFO - Epoch [1][3300/29317]	lr: 9.689e-07, eta: 4 days, 2:36:59, time: 0.482, data_time: 0.034, memory: 11094, loss_rpn_cls: 0.0633, loss_rpn_bbox: 0.0632, loss_cls: 0.3562, acc: 92.0652, loss_bbox: 0.2601, loss_mask: 0.4015, loss: 1.1443
2022-04-15 12:01:10,008 - mmdet - INFO - Epoch [1][3350/29317]	lr: 9.689e-07, eta: 4 days, 2:36:29, time: 0.486, data_time: 0.039, memory: 11094, loss_rpn_cls: 0.0604, loss_rpn_bbox: 0.0619, loss_cls: 0.3519, acc: 92.1238, loss_bbox: 0.2596, loss_mask: 0.3940, loss: 1.1278
2022-04-15 12:01:33,977 - mmdet - INFO - Epoch [1][3400/29317]	lr: 9.689e-07, eta: 4 days, 2:34:47, time: 0.479, data_time: 0.034, memory: 11094, loss_rpn_cls: 0.0580, loss_rpn_bbox: 0.0585, loss_cls: 0.3434, acc: 92.1223, loss_bbox: 0.2566, loss_mask: 0.3938, loss: 1.1103
2022-04-15 12:01:58,911 - mmdet - INFO - Epoch [1][3450/29317]	lr: 9.689e-07, eta: 4 days, 2:36:32, time: 0.499, data_time: 0.034, memory: 11094, loss_rpn_cls: 0.0579, loss_rpn_bbox: 0.0601, loss_cls: 0.3779, acc: 91.3289, loss_bbox: 0.2794, loss_mask: 0.3975, loss: 1.1728
2022-04-15 12:02:23,234 - mmdet - INFO - Epoch [1][3500/29317]	lr: 9.689e-07, eta: 4 days, 2:36:05, time: 0.486, data_time: 0.037, memory: 11094, loss_rpn_cls: 0.0606, loss_rpn_bbox: 0.0623, loss_cls: 0.3630, acc: 91.6775, loss_bbox: 0.2723, loss_mask: 0.3977, loss: 1.1559
2022-04-15 12:02:46,710 - mmdet - INFO - Epoch [1][3550/29317]	lr: 9.689e-07, eta: 4 days, 2:32:45, time: 0.470, data_time: 0.036, memory: 11094, loss_rpn_cls: 0.0542, loss_rpn_bbox: 0.0585, loss_cls: 0.3564, acc: 91.7632, loss_bbox: 0.2691, loss_mask: 0.3867, loss: 1.1250
2022-04-15 12:03:11,277 - mmdet - INFO - Epoch [1][3600/29317]	lr: 9.689e-07, eta: 4 days, 2:33:11, time: 0.491, data_time: 0.032, memory: 11094, loss_rpn_cls: 0.0630, loss_rpn_bbox: 0.0638, loss_cls: 0.3429, acc: 92.0475, loss_bbox: 0.2622, loss_mask: 0.3981, loss: 1.1299
2022-04-15 12:03:36,109 - mmdet - INFO - Epoch [1][3650/29317]	lr: 9.689e-07, eta: 4 days, 2:34:28, time: 0.497, data_time: 0.039, memory: 11094, loss_rpn_cls: 0.0619, loss_rpn_bbox: 0.0632, loss_cls: 0.3420, acc: 91.9456, loss_bbox: 0.2639, loss_mask: 0.3873, loss: 1.1183
2022-04-15 12:04:00,809 - mmdet - INFO - Epoch [1][3700/29317]	lr: 9.689e-07, eta: 4 days, 2:35:17, time: 0.494, data_time: 0.036, memory: 11094, loss_rpn_cls: 0.0581, loss_rpn_bbox: 0.0600, loss_cls: 0.3599, acc: 91.6147, loss_bbox: 0.2697, loss_mask: 0.3958, loss: 1.1434
2022-04-15 12:04:25,629 - mmdet - INFO - Epoch [1][3750/29317]	lr: 9.689e-07, eta: 4 days, 2:36:27, time: 0.496, data_time: 0.041, memory: 11094, loss_rpn_cls: 0.0633, loss_rpn_bbox: 0.0661, loss_cls: 0.3568, acc: 91.5486, loss_bbox: 0.2758, loss_mask: 0.3897, loss: 1.1517
2022-04-15 12:04:49,557 - mmdet - INFO - Epoch [1][3800/29317]	lr: 9.689e-07, eta: 4 days, 2:34:42, time: 0.478, data_time: 0.031, memory: 11094, loss_rpn_cls: 0.0587, loss_rpn_bbox: 0.0583, loss_cls: 0.3538, acc: 91.8787, loss_bbox: 0.2615, loss_mask: 0.3828, loss: 1.1150
2022-04-15 12:05:14,601 - mmdet - INFO - Epoch [1][3850/29317]	lr: 9.689e-07, eta: 4 days, 2:36:32, time: 0.501, data_time: 0.036, memory: 11094, loss_rpn_cls: 0.0649, loss_rpn_bbox: 0.0611, loss_cls: 0.3384, acc: 92.0857, loss_bbox: 0.2560, loss_mask: 0.3856, loss: 1.1060
2022-04-15 12:05:39,129 - mmdet - INFO - Epoch [1][3900/29317]	lr: 9.689e-07, eta: 4 days, 2:36:30, time: 0.489, data_time: 0.035, memory: 11094, loss_rpn_cls: 0.0587, loss_rpn_bbox: 0.0609, loss_cls: 0.3450, acc: 91.7568, loss_bbox: 0.2654, loss_mask: 0.3994, loss: 1.1293
2022-04-15 12:06:03,864 - mmdet - INFO - Epoch [1][3950/29317]	lr: 9.689e-07, eta: 4 days, 2:37:29, time: 0.496, data_time: 0.041, memory: 11094, loss_rpn_cls: 0.0622, loss_rpn_bbox: 0.0668, loss_cls: 0.3552, acc: 91.4890, loss_bbox: 0.2758, loss_mask: 0.3884, loss: 1.1483
2022-04-15 12:06:28,899 - mmdet - INFO - Exp name: vitdet_sfp_100e_fp16_coco.py
2022-04-15 12:06:28,899 - mmdet - INFO - Epoch [1][4000/29317]	lr: 9.689e-07, eta: 4 days, 2:39:08, time: 0.501, data_time: 0.035, memory: 11094, loss_rpn_cls: 0.0612, loss_rpn_bbox: 0.0620, loss_cls: 0.3361, acc: 91.9656, loss_bbox: 0.2600, loss_mask: 0.3854, loss: 1.1046
2022-04-15 12:06:52,979 - mmdet - INFO - Epoch [1][4050/29317]	lr: 9.689e-07, eta: 4 days, 2:37:54, time: 0.482, data_time: 0.036, memory: 11094, loss_rpn_cls: 0.0555, loss_rpn_bbox: 0.0576, loss_cls: 0.3368, acc: 92.0706, loss_bbox: 0.2553, loss_mask: 0.3956, loss: 1.1007
2022-04-15 12:07:16,899 - mmdet - INFO - Epoch [1][4100/29317]	lr: 9.689e-07, eta: 4 days, 2:36:09, time: 0.478, data_time: 0.033, memory: 11094, loss_rpn_cls: 0.0634, loss_rpn_bbox: 0.0627, loss_cls: 0.3427, acc: 91.9998, loss_bbox: 0.2564, loss_mask: 0.3910, loss: 1.1163
2022-04-15 12:07:41,344 - mmdet - INFO - Epoch [1][4150/29317]	lr: 9.689e-07, eta: 4 days, 2:36:03, time: 0.489, data_time: 0.039, memory: 11094, loss_rpn_cls: 0.0561, loss_rpn_bbox: 0.0581, loss_cls: 0.3442, acc: 91.9409, loss_bbox: 0.2582, loss_mask: 0.3835, loss: 1.1000
2022-04-15 12:08:05,210 - mmdet - INFO - Epoch [1][4200/29317]	lr: 9.689e-07, eta: 4 days, 2:34:14, time: 0.477, data_time: 0.035, memory: 11094, loss_rpn_cls: 0.0606, loss_rpn_bbox: 0.0599, loss_cls: 0.3459, acc: 91.7937, loss_bbox: 0.2618, loss_mask: 0.3867, loss: 1.1149
2022-04-15 12:08:29,692 - mmdet - INFO - Epoch [1][4250/29317]	lr: 9.689e-07, eta: 4 days, 2:34:13, time: 0.490, data_time: 0.034, memory: 11094, loss_rpn_cls: 0.0545, loss_rpn_bbox: 0.0571, loss_cls: 0.3349, acc: 92.1042, loss_bbox: 0.2533, loss_mask: 0.3961, loss: 1.0960
2022-04-15 12:08:53,616 - mmdet - INFO - Epoch [1][4300/29317]	lr: 9.689e-07, eta: 4 days, 2:32:34, time: 0.478, data_time: 0.033, memory: 11094, loss_rpn_cls: 0.0553, loss_rpn_bbox: 0.0609, loss_cls: 0.3394, acc: 91.7488, loss_bbox: 0.2619, loss_mask: 0.3769, loss: 1.0944
2022-04-15 12:09:18,329 - mmdet - INFO - Epoch [1][4350/29317]	lr: 9.689e-07, eta: 4 days, 2:33:14, time: 0.495, data_time: 0.037, memory: 11094, loss_rpn_cls: 0.0561, loss_rpn_bbox: 0.0595, loss_cls: 0.3336, acc: 92.1348, loss_bbox: 0.2554, loss_mask: 0.3792, loss: 1.0838
2022-04-15 12:09:43,243 - mmdet - INFO - Epoch [1][4400/29317]	lr: 9.689e-07, eta: 4 days, 2:34:23, time: 0.498, data_time: 0.043, memory: 11094, loss_rpn_cls: 0.0581, loss_rpn_bbox: 0.0640, loss_cls: 0.3490, acc: 91.5825, loss_bbox: 0.2682, loss_mask: 0.3823, loss: 1.1215
2022-04-15 12:10:07,407 - mmdet - INFO - Epoch [1][4450/29317]	lr: 9.689e-07, eta: 4 days, 2:33:27, time: 0.483, data_time: 0.036, memory: 11094, loss_rpn_cls: 0.0565, loss_rpn_bbox: 0.0605, loss_cls: 0.3262, acc: 92.0129, loss_bbox: 0.2587, loss_mask: 0.3848, loss: 1.0866
2022-04-15 12:10:32,443 - mmdet - INFO - Epoch [1][4500/29317]	lr: 9.689e-07, eta: 4 days, 2:34:53, time: 0.501, data_time: 0.043, memory: 11094, loss_rpn_cls: 0.0648, loss_rpn_bbox: 0.0661, loss_cls: 0.3412, acc: 91.6475, loss_bbox: 0.2655, loss_mask: 0.3836, loss: 1.1213
2022-04-15 12:10:56,734 - mmdet - INFO - Epoch [1][4550/29317]	lr: 9.689e-07, eta: 4 days, 2:34:18, time: 0.486, data_time: 0.034, memory: 11094, loss_rpn_cls: 0.0607, loss_rpn_bbox: 0.0641, loss_cls: 0.3453, acc: 91.5559, loss_bbox: 0.2690, loss_mask: 0.3835, loss: 1.1227
2022-04-15 12:11:21,349 - mmdet - INFO - Epoch [1][4600/29317]	lr: 9.689e-07, eta: 4 days, 2:34:32, time: 0.492, data_time: 0.037, memory: 11094, loss_rpn_cls: 0.0588, loss_rpn_bbox: 0.0641, loss_cls: 0.3399, acc: 91.8087, loss_bbox: 0.2597, loss_mask: 0.3804, loss: 1.1029
2022-04-15 12:11:45,629 - mmdet - INFO - Epoch [1][4650/29317]	lr: 9.689e-07, eta: 4 days, 2:33:57, time: 0.486, data_time: 0.037, memory: 11094, loss_rpn_cls: 0.0582, loss_rpn_bbox: 0.0636, loss_cls: 0.3460, acc: 91.5872, loss_bbox: 0.2680, loss_mask: 0.3847, loss: 1.1206
2022-04-15 12:12:09,597 - mmdet - INFO - Epoch [1][4700/29317]	lr: 9.689e-07, eta: 4 days, 2:32:31, time: 0.479, data_time: 0.031, memory: 11094, loss_rpn_cls: 0.0532, loss_rpn_bbox: 0.0572, loss_cls: 0.3342, acc: 91.9600, loss_bbox: 0.2546, loss_mask: 0.3793, loss: 1.0785
2022-04-15 12:12:33,938 - mmdet - INFO - Epoch [1][4750/29317]	lr: 9.689e-07, eta: 4 days, 2:32:04, time: 0.487, data_time: 0.034, memory: 11094, loss_rpn_cls: 0.0582, loss_rpn_bbox: 0.0618, loss_cls: 0.3521, acc: 91.4412, loss_bbox: 0.2700, loss_mask: 0.3774, loss: 1.1195
2022-04-15 12:12:58,998 - mmdet - INFO - Epoch [1][4800/29317]	lr: 9.689e-07, eta: 4 days, 2:33:26, time: 0.501, data_time: 0.033, memory: 11094, loss_rpn_cls: 0.0590, loss_rpn_bbox: 0.0633, loss_cls: 0.3247, acc: 92.0852, loss_bbox: 0.2536, loss_mask: 0.3753, loss: 1.0759
2022-04-15 12:13:23,136 - mmdet - INFO - Epoch [1][4850/29317]	lr: 9.689e-07, eta: 4 days, 2:32:28, time: 0.483, data_time: 0.039, memory: 11094, loss_rpn_cls: 0.0520, loss_rpn_bbox: 0.0591, loss_cls: 0.3376, acc: 91.6516, loss_bbox: 0.2684, loss_mask: 0.3752, loss: 1.0923
2022-04-15 12:13:47,677 - mmdet - INFO - Epoch [1][4900/29317]	lr: 9.689e-07, eta: 4 days, 2:32:30, time: 0.491, data_time: 0.037, memory: 11094, loss_rpn_cls: 0.0561, loss_rpn_bbox: 0.0626, loss_cls: 0.3366, acc: 91.6638, loss_bbox: 0.2645, loss_mask: 0.3816, loss: 1.1015
2022-04-15 12:14:12,191 - mmdet - INFO - Epoch [1][4950/29317]	lr: 9.689e-07, eta: 4 days, 2:32:28, time: 0.490, data_time: 0.038, memory: 11094, loss_rpn_cls: 0.0555, loss_rpn_bbox: 0.0571, loss_cls: 0.3299, acc: 91.9438, loss_bbox: 0.2558, loss_mask: 0.3740, loss: 1.0723
2022-04-15 12:14:36,357 - mmdet - INFO - Exp name: vitdet_sfp_100e_fp16_coco.py
2022-04-15 12:14:36,357 - mmdet - INFO - Epoch [1][5000/29317]	lr: 9.689e-07, eta: 4 days, 2:31:34, time: 0.483, data_time: 0.039, memory: 11094, loss_rpn_cls: 0.0530, loss_rpn_bbox: 0.0591, loss_cls: 0.3432, acc: 91.5872, loss_bbox: 0.2643, loss_mask: 0.3683, loss: 1.0878
2022-04-15 12:15:00,309 - mmdet - INFO - Epoch [1][5050/29317]	lr: 9.689e-07, eta: 4 days, 2:30:11, time: 0.479, data_time: 0.035, memory: 11094, loss_rpn_cls: 0.0535, loss_rpn_bbox: 0.0597, loss_cls: 0.3321, acc: 91.8599, loss_bbox: 0.2626, loss_mask: 0.3779, loss: 1.0859
2022-04-15 12:15:25,341 - mmdet - INFO - Epoch [1][5100/29317]	lr: 9.689e-07, eta: 4 days, 2:31:22, time: 0.501, data_time: 0.037, memory: 11094, loss_rpn_cls: 0.0570, loss_rpn_bbox: 0.0671, loss_cls: 0.3494, acc: 91.3792, loss_bbox: 0.2768, loss_mask: 0.3755, loss: 1.1258
2022-04-15 12:15:49,673 - mmdet - INFO - Epoch [1][5150/29317]	lr: 9.689e-07, eta: 4 days, 2:30:53, time: 0.487, data_time: 0.037, memory: 11094, loss_rpn_cls: 0.0527, loss_rpn_bbox: 0.0599, loss_cls: 0.3278, acc: 91.7749, loss_bbox: 0.2656, loss_mask: 0.3666, loss: 1.0726
2022-04-15 12:16:14,510 - mmdet - INFO - Epoch [1][5200/29317]	lr: 9.689e-07, eta: 4 days, 2:31:32, time: 0.496, data_time: 0.035, memory: 11094, loss_rpn_cls: 0.0561, loss_rpn_bbox: 0.0603, loss_cls: 0.3295, acc: 91.7463, loss_bbox: 0.2637, loss_mask: 0.3704, loss: 1.0800
2022-04-15 12:16:38,576 - mmdet - INFO - Epoch [1][5250/29317]	lr: 9.689e-07, eta: 4 days, 2:30:28, time: 0.482, data_time: 0.037, memory: 11094, loss_rpn_cls: 0.0575, loss_rpn_bbox: 0.0598, loss_cls: 0.3323, acc: 91.7617, loss_bbox: 0.2569, loss_mask: 0.3716, loss: 1.0780
2022-04-15 12:17:03,088 - mmdet - INFO - Epoch [1][5300/29317]	lr: 9.689e-07, eta: 4 days, 2:30:23, time: 0.490, data_time: 0.037, memory: 11094, loss_rpn_cls: 0.0557, loss_rpn_bbox: 0.0616, loss_cls: 0.3269, acc: 91.8806, loss_bbox: 0.2587, loss_mask: 0.3713, loss: 1.0743
2022-04-15 12:17:27,755 - mmdet - INFO - Epoch [1][5350/29317]	lr: 9.689e-07, eta: 4 days, 2:30:39, time: 0.493, data_time: 0.032, memory: 11094, loss_rpn_cls: 0.0542, loss_rpn_bbox: 0.0608, loss_cls: 0.3231, acc: 91.8911, loss_bbox: 0.2609, loss_mask: 0.3730, loss: 1.0719
2022-04-15 12:17:51,926 - mmdet - INFO - Epoch [1][5400/29317]	lr: 9.689e-07, eta: 4 days, 2:29:48, time: 0.483, data_time: 0.039, memory: 11094, loss_rpn_cls: 0.0625, loss_rpn_bbox: 0.0608, loss_cls: 0.3241, acc: 92.0388, loss_bbox: 0.2600, loss_mask: 0.3732, loss: 1.0808
2022-04-15 12:18:16,142 - mmdet - INFO - Epoch [1][5450/29317]	lr: 9.689e-07, eta: 4 days, 2:29:03, time: 0.484, data_time: 0.044, memory: 11094, loss_rpn_cls: 0.0539, loss_rpn_bbox: 0.0594, loss_cls: 0.3359, acc: 91.5435, loss_bbox: 0.2705, loss_mask: 0.3628, loss: 1.0824
2022-04-15 12:18:40,982 - mmdet - INFO - Epoch [1][5500/29317]	lr: 9.689e-07, eta: 4 days, 2:29:41, time: 0.497, data_time: 0.031, memory: 11094, loss_rpn_cls: 0.0527, loss_rpn_bbox: 0.0616, loss_cls: 0.3386, acc: 91.5859, loss_bbox: 0.2691, loss_mask: 0.3689, loss: 1.0909
2022-04-15 12:19:05,681 - mmdet - INFO - Epoch [1][5550/29317]	lr: 9.689e-07, eta: 4 days, 2:29:59, time: 0.494, data_time: 0.040, memory: 11094, loss_rpn_cls: 0.0560, loss_rpn_bbox: 0.0625, loss_cls: 0.3291, acc: 91.6689, loss_bbox: 0.2622, loss_mask: 0.3710, loss: 1.0807
2022-04-15 12:19:30,107 - mmdet - INFO - Epoch [1][5600/29317]	lr: 9.689e-07, eta: 4 days, 2:29:41, time: 0.488, data_time: 0.039, memory: 11094, loss_rpn_cls: 0.0515, loss_rpn_bbox: 0.0557, loss_cls: 0.3213, acc: 91.9629, loss_bbox: 0.2520, loss_mask: 0.3586, loss: 1.0390
2022-04-15 12:19:54,389 - mmdet - INFO - Epoch [1][5650/29317]	lr: 9.689e-07, eta: 4 days, 2:29:05, time: 0.486, data_time: 0.039, memory: 11094, loss_rpn_cls: 0.0548, loss_rpn_bbox: 0.0591, loss_cls: 0.3291, acc: 91.7507, loss_bbox: 0.2597, loss_mask: 0.3693, loss: 1.0720
2022-04-15 12:20:18,900 - mmdet - INFO - Epoch [1][5700/29317]	lr: 9.689e-07, eta: 4 days, 2:28:58, time: 0.490, data_time: 0.045, memory: 11094, loss_rpn_cls: 0.0562, loss_rpn_bbox: 0.0625, loss_cls: 0.3377, acc: 91.3750, loss_bbox: 0.2745, loss_mask: 0.3637, loss: 1.0945
2022-04-15 12:20:43,279 - mmdet - INFO - Epoch [1][5750/29317]	lr: 9.689e-07, eta: 4 days, 2:28:34, time: 0.488, data_time: 0.037, memory: 11094, loss_rpn_cls: 0.0523, loss_rpn_bbox: 0.0618, loss_cls: 0.3220, acc: 91.7361, loss_bbox: 0.2639, loss_mask: 0.3602, loss: 1.0601
2022-04-15 12:21:07,806 - mmdet - INFO - Epoch [1][5800/29317]	lr: 9.689e-07, eta: 4 days, 2:28:27, time: 0.490, data_time: 0.040, memory: 11094, loss_rpn_cls: 0.0500, loss_rpn_bbox: 0.0550, loss_cls: 0.3213, acc: 91.9600, loss_bbox: 0.2570, loss_mask: 0.3595, loss: 1.0428
2022-04-15 12:21:32,071 - mmdet - INFO - Epoch [1][5850/29317]	lr: 9.689e-07, eta: 4 days, 2:27:50, time: 0.486, data_time: 0.036, memory: 11094, loss_rpn_cls: 0.0511, loss_rpn_bbox: 0.0573, loss_cls: 0.3148, acc: 91.9824, loss_bbox: 0.2557, loss_mask: 0.3650, loss: 1.0439
2022-04-15 12:21:56,190 - mmdet - INFO - Epoch [1][5900/29317]	lr: 9.689e-07, eta: 4 days, 2:26:54, time: 0.482, data_time: 0.041, memory: 11094, loss_rpn_cls: 0.0506, loss_rpn_bbox: 0.0575, loss_cls: 0.3221, acc: 91.8796, loss_bbox: 0.2545, loss_mask: 0.3643, loss: 1.0489
2022-04-15 12:22:20,807 - mmdet - INFO - Epoch [1][5950/29317]	lr: 9.689e-07, eta: 4 days, 2:26:59, time: 0.492, data_time: 0.040, memory: 11094, loss_rpn_cls: 0.0540, loss_rpn_bbox: 0.0575, loss_cls: 0.3279, acc: 91.7161, loss_bbox: 0.2562, loss_mask: 0.3686, loss: 1.0640
2022-04-15 12:22:45,154 - mmdet - INFO - Exp name: vitdet_sfp_100e_fp16_coco.py
2022-04-15 12:22:45,154 - mmdet - INFO - Epoch [1][6000/29317]	lr: 9.689e-07, eta: 4 days, 2:26:30, time: 0.487, data_time: 0.041, memory: 11094, loss_rpn_cls: 0.0532, loss_rpn_bbox: 0.0598, loss_cls: 0.3184, acc: 91.7410, loss_bbox: 0.2608, loss_mask: 0.3682, loss: 1.0604
2022-04-15 12:23:09,538 - mmdet - INFO - Epoch [1][6050/29317]	lr: 9.689e-07, eta: 4 days, 2:26:07, time: 0.488, data_time: 0.039, memory: 11094, loss_rpn_cls: 0.0532, loss_rpn_bbox: 0.0613, loss_cls: 0.3229, acc: 91.7627, loss_bbox: 0.2601, loss_mask: 0.3612, loss: 1.0586
2022-04-15 12:23:34,867 - mmdet - INFO - Epoch [1][6100/29317]	lr: 9.689e-07, eta: 4 days, 2:27:36, time: 0.507, data_time: 0.040, memory: 11094, loss_rpn_cls: 0.0529, loss_rpn_bbox: 0.0613, loss_cls: 0.3251, acc: 91.6382, loss_bbox: 0.2636, loss_mask: 0.3589, loss: 1.0618
2022-04-15 12:23:59,071 - mmdet - INFO - Epoch [1][6150/29317]	lr: 9.689e-07, eta: 4 days, 2:26:51, time: 0.484, data_time: 0.037, memory: 11094, loss_rpn_cls: 0.0515, loss_rpn_bbox: 0.0573, loss_cls: 0.3232, acc: 91.7368, loss_bbox: 0.2619, loss_mask: 0.3593, loss: 1.0532
2022-04-15 12:24:23,154 - mmdet - INFO - Epoch [1][6200/29317]	lr: 9.689e-07, eta: 4 days, 2:25:51, time: 0.482, data_time: 0.040, memory: 11094, loss_rpn_cls: 0.0489, loss_rpn_bbox: 0.0567, loss_cls: 0.3145, acc: 91.8203, loss_bbox: 0.2582, loss_mask: 0.3528, loss: 1.0312
2022-04-15 12:24:47,600 - mmdet - INFO - Epoch [1][6250/29317]	lr: 9.689e-07, eta: 4 days, 2:25:34, time: 0.489, data_time: 0.043, memory: 11094, loss_rpn_cls: 0.0486, loss_rpn_bbox: 0.0546, loss_cls: 0.3237, acc: 91.8574, loss_bbox: 0.2533, loss_mask: 0.3641, loss: 1.0443
2022-04-15 12:25:11,936 - mmdet - INFO - Epoch [1][6300/29317]	lr: 9.689e-07, eta: 4 days, 2:25:05, time: 0.487, data_time: 0.036, memory: 11094, loss_rpn_cls: 0.0518, loss_rpn_bbox: 0.0579, loss_cls: 0.3183, acc: 91.9480, loss_bbox: 0.2521, loss_mask: 0.3595, loss: 1.0395
2022-04-15 12:25:36,202 - mmdet - INFO - Epoch [1][6350/29317]	lr: 9.689e-07, eta: 4 days, 2:24:27, time: 0.485, data_time: 0.032, memory: 11094, loss_rpn_cls: 0.0511, loss_rpn_bbox: 0.0552, loss_cls: 0.3076, acc: 92.0935, loss_bbox: 0.2492, loss_mask: 0.3561, loss: 1.0193
2022-04-15 12:26:00,598 - mmdet - INFO - Epoch [1][6400/29317]	lr: 9.689e-07, eta: 4 days, 2:24:05, time: 0.488, data_time: 0.042, memory: 11094, loss_rpn_cls: 0.0510, loss_rpn_bbox: 0.0583, loss_cls: 0.3154, acc: 91.8779, loss_bbox: 0.2562, loss_mask: 0.3579, loss: 1.0388
2022-04-15 12:26:25,013 - mmdet - INFO - Epoch [1][6450/29317]	lr: 9.689e-07, eta: 4 days, 2:23:44, time: 0.488, data_time: 0.036, memory: 11094, loss_rpn_cls: 0.0524, loss_rpn_bbox: 0.0586, loss_cls: 0.3077, acc: 92.2117, loss_bbox: 0.2449, loss_mask: 0.3534, loss: 1.0169
2022-04-15 12:26:49,151 - mmdet - INFO - Epoch [1][6500/29317]	lr: 9.689e-07, eta: 4 days, 2:22:53, time: 0.483, data_time: 0.031, memory: 11094, loss_rpn_cls: 0.0474, loss_rpn_bbox: 0.0575, loss_cls: 0.3174, acc: 91.7925, loss_bbox: 0.2618, loss_mask: 0.3645, loss: 1.0486
2022-04-15 12:27:13,661 - mmdet - INFO - Epoch [1][6550/29317]	lr: 9.689e-07, eta: 4 days, 2:22:43, time: 0.490, data_time: 0.044, memory: 11094, loss_rpn_cls: 0.0508, loss_rpn_bbox: 0.0585, loss_cls: 0.3200, acc: 91.7781, loss_bbox: 0.2595, loss_mask: 0.3592, loss: 1.0480
2022-04-15 12:27:38,375 - mmdet - INFO - Epoch [1][6600/29317]	lr: 9.689e-07, eta: 4 days, 2:22:55, time: 0.494, data_time: 0.036, memory: 11094, loss_rpn_cls: 0.0527, loss_rpn_bbox: 0.0589, loss_cls: 0.3183, acc: 91.7983, loss_bbox: 0.2567, loss_mask: 0.3507, loss: 1.0373
2022-04-15 12:28:02,887 - mmdet - INFO - Epoch [1][6650/29317]	lr: 9.689e-07, eta: 4 days, 2:22:46, time: 0.490, data_time: 0.034, memory: 11094, loss_rpn_cls: 0.0536, loss_rpn_bbox: 0.0588, loss_cls: 0.3208, acc: 91.7327, loss_bbox: 0.2590, loss_mask: 0.3580, loss: 1.0502
2022-04-15 12:28:27,167 - mmdet - INFO - Epoch [1][6700/29317]	lr: 9.689e-07, eta: 4 days, 2:22:10, time: 0.486, data_time: 0.038, memory: 11094, loss_rpn_cls: 0.0530, loss_rpn_bbox: 0.0568, loss_cls: 0.3110, acc: 92.0789, loss_bbox: 0.2469, loss_mask: 0.3608, loss: 1.0285
2022-04-15 12:28:52,401 - mmdet - INFO - Epoch [1][6750/29317]	lr: 9.689e-07, eta: 4 days, 2:23:17, time: 0.505, data_time: 0.040, memory: 11094, loss_rpn_cls: 0.0501, loss_rpn_bbox: 0.0565, loss_cls: 0.2959, acc: 92.3259, loss_bbox: 0.2413, loss_mask: 0.3520, loss: 0.9958
2022-04-15 12:29:17,117 - mmdet - INFO - Epoch [1][6800/29317]	lr: 9.689e-07, eta: 4 days, 2:23:28, time: 0.494, data_time: 0.041, memory: 11094, loss_rpn_cls: 0.0524, loss_rpn_bbox: 0.0633, loss_cls: 0.3057, acc: 92.0769, loss_bbox: 0.2489, loss_mask: 0.3554, loss: 1.0258
2022-04-15 12:29:41,564 - mmdet - INFO - Epoch [1][6850/29317]	lr: 9.689e-07, eta: 4 days, 2:23:09, time: 0.489, data_time: 0.039, memory: 11094, loss_rpn_cls: 0.0480, loss_rpn_bbox: 0.0575, loss_cls: 0.3130, acc: 91.6931, loss_bbox: 0.2606, loss_mask: 0.3537, loss: 1.0328
2022-04-15 12:30:06,207 - mmdet - INFO - Epoch [1][6900/29317]	lr: 9.689e-07, eta: 4 days, 2:23:11, time: 0.493, data_time: 0.036, memory: 11094, loss_rpn_cls: 0.0549, loss_rpn_bbox: 0.0627, loss_cls: 0.3114, acc: 91.7988, loss_bbox: 0.2559, loss_mask: 0.3543, loss: 1.0392
2022-04-15 12:30:30,875 - mmdet - INFO - Epoch [1][6950/29317]	lr: 9.689e-07, eta: 4 days, 2:23:16, time: 0.493, data_time: 0.038, memory: 11094, loss_rpn_cls: 0.0517, loss_rpn_bbox: 0.0615, loss_cls: 0.3097, acc: 91.8376, loss_bbox: 0.2582, loss_mask: 0.3470, loss: 1.0280
2022-04-15 12:30:55,285 - mmdet - INFO - Exp name: vitdet_sfp_100e_fp16_coco.py
2022-04-15 12:30:55,285 - mmdet - INFO - Epoch [1][7000/29317]	lr: 9.689e-07, eta: 4 days, 2:22:53, time: 0.488, data_time: 0.043, memory: 11094, loss_rpn_cls: 0.0497, loss_rpn_bbox: 0.0570, loss_cls: 0.3049, acc: 91.8748, loss_bbox: 0.2571, loss_mask: 0.3632, loss: 1.0320
2022-04-15 12:31:19,944 - mmdet - INFO - Epoch [1][7050/29317]	lr: 9.689e-07, eta: 4 days, 2:22:56, time: 0.493, data_time: 0.040, memory: 11094, loss_rpn_cls: 0.0548, loss_rpn_bbox: 0.0613, loss_cls: 0.3204, acc: 91.7524, loss_bbox: 0.2573, loss_mask: 0.3545, loss: 1.0482
2022-04-15 12:31:44,681 - mmdet - INFO - Epoch [1][7100/29317]	lr: 9.689e-07, eta: 4 days, 2:23:06, time: 0.495, data_time: 0.035, memory: 11094, loss_rpn_cls: 0.0507, loss_rpn_bbox: 0.0570, loss_cls: 0.3106, acc: 91.8816, loss_bbox: 0.2520, loss_mask: 0.3478, loss: 1.0182
2022-04-15 12:32:08,986 - mmdet - INFO - Epoch [1][7150/29317]	lr: 9.689e-07, eta: 4 days, 2:22:32, time: 0.486, data_time: 0.047, memory: 11094, loss_rpn_cls: 0.0519, loss_rpn_bbox: 0.0604, loss_cls: 0.3165, acc: 91.7065, loss_bbox: 0.2536, loss_mask: 0.3559, loss: 1.0383
2022-04-15 12:32:33,793 - mmdet - INFO - Epoch [1][7200/29317]	lr: 9.689e-07, eta: 4 days, 2:22:49, time: 0.496, data_time: 0.037, memory: 11094, loss_rpn_cls: 0.0541, loss_rpn_bbox: 0.0624, loss_cls: 0.3149, acc: 91.7058, loss_bbox: 0.2582, loss_mask: 0.3567, loss: 1.0464
2022-04-15 12:32:58,039 - mmdet - INFO - Epoch [1][7250/29317]	lr: 9.689e-07, eta: 4 days, 2:22:09, time: 0.485, data_time: 0.041, memory: 11094, loss_rpn_cls: 0.0484, loss_rpn_bbox: 0.0581, loss_cls: 0.2966, acc: 92.2986, loss_bbox: 0.2428, loss_mask: 0.3495, loss: 0.9953
2022-04-15 12:33:22,330 - mmdet - INFO - Epoch [1][7300/29317]	lr: 9.689e-07, eta: 4 days, 2:21:33, time: 0.486, data_time: 0.035, memory: 11094, loss_rpn_cls: 0.0519, loss_rpn_bbox: 0.0581, loss_cls: 0.3009, acc: 92.0554, loss_bbox: 0.2482, loss_mask: 0.3403, loss: 0.9995
2022-04-15 12:33:47,026 - mmdet - INFO - Epoch [1][7350/29317]	lr: 9.689e-07, eta: 4 days, 2:21:38, time: 0.494, data_time: 0.041, memory: 11094, loss_rpn_cls: 0.0484, loss_rpn_bbox: 0.0606, loss_cls: 0.3133, acc: 91.7693, loss_bbox: 0.2606, loss_mask: 0.3402, loss: 1.0232
2022-04-15 12:34:11,654 - mmdet - INFO - Epoch [1][7400/29317]	lr: 9.689e-07, eta: 4 days, 2:21:36, time: 0.493, data_time: 0.040, memory: 11094, loss_rpn_cls: 0.0478, loss_rpn_bbox: 0.0574, loss_cls: 0.3194, acc: 91.7808, loss_bbox: 0.2559, loss_mask: 0.3457, loss: 1.0261
2022-04-15 12:34:36,214 - mmdet - INFO - Epoch [1][7450/29317]	lr: 9.689e-07, eta: 4 days, 2:21:27, time: 0.491, data_time: 0.041, memory: 11094, loss_rpn_cls: 0.0509, loss_rpn_bbox: 0.0574, loss_cls: 0.3134, acc: 91.7178, loss_bbox: 0.2590, loss_mask: 0.3566, loss: 1.0373
2022-04-15 12:35:00,624 - mmdet - INFO - Epoch [1][7500/29317]	lr: 9.689e-07, eta: 4 days, 2:21:01, time: 0.488, data_time: 0.038, memory: 11094, loss_rpn_cls: 0.0510, loss_rpn_bbox: 0.0591, loss_cls: 0.3101, acc: 91.8621, loss_bbox: 0.2506, loss_mask: 0.3435, loss: 1.0143
2022-04-15 12:35:24,967 - mmdet - INFO - Epoch [1][7550/29317]	lr: 9.689e-07, eta: 4 days, 2:20:33, time: 0.487, data_time: 0.035, memory: 11094, loss_rpn_cls: 0.0472, loss_rpn_bbox: 0.0536, loss_cls: 0.3026, acc: 92.0862, loss_bbox: 0.2442, loss_mask: 0.3414, loss: 0.9891
2022-04-15 12:35:49,363 - mmdet - INFO - Epoch [1][7600/29317]	lr: 9.689e-07, eta: 4 days, 2:20:08, time: 0.488, data_time: 0.041, memory: 11094, loss_rpn_cls: 0.0462, loss_rpn_bbox: 0.0580, loss_cls: 0.2970, acc: 92.1687, loss_bbox: 0.2477, loss_mask: 0.3412, loss: 0.9901
2022-04-15 12:36:14,032 - mmdet - INFO - Epoch [1][7650/29317]	lr: 9.689e-07, eta: 4 days, 2:20:08, time: 0.493, data_time: 0.036, memory: 11094, loss_rpn_cls: 0.0489, loss_rpn_bbox: 0.0571, loss_cls: 0.3135, acc: 91.7205, loss_bbox: 0.2555, loss_mask: 0.3490, loss: 1.0241
2022-04-15 12:36:38,489 - mmdet - INFO - Epoch [1][7700/29317]	lr: 9.689e-07, eta: 4 days, 2:19:49, time: 0.489, data_time: 0.043, memory: 11094, loss_rpn_cls: 0.0505, loss_rpn_bbox: 0.0588, loss_cls: 0.3133, acc: 91.8667, loss_bbox: 0.2526, loss_mask: 0.3509, loss: 1.0261
2022-04-15 12:37:02,801 - mmdet - INFO - Epoch [1][7750/29317]	lr: 9.689e-07, eta: 4 days, 2:19:16, time: 0.486, data_time: 0.036, memory: 11094, loss_rpn_cls: 0.0501, loss_rpn_bbox: 0.0534, loss_cls: 0.3054, acc: 92.2117, loss_bbox: 0.2420, loss_mask: 0.3415, loss: 0.9924
2022-04-15 12:37:27,141 - mmdet - INFO - Epoch [1][7800/29317]	lr: 9.689e-07, eta: 4 days, 2:18:44, time: 0.487, data_time: 0.037, memory: 11094, loss_rpn_cls: 0.0532, loss_rpn_bbox: 0.0602, loss_cls: 0.3078, acc: 91.8955, loss_bbox: 0.2498, loss_mask: 0.3437, loss: 1.0147
2022-04-15 12:37:51,841 - mmdet - INFO - Epoch [1][7850/29317]	lr: 9.689e-07, eta: 4 days, 2:18:48, time: 0.494, data_time: 0.038, memory: 11094, loss_rpn_cls: 0.0453, loss_rpn_bbox: 0.0557, loss_cls: 0.2905, acc: 92.3293, loss_bbox: 0.2390, loss_mask: 0.3439, loss: 0.9744
2022-04-15 12:38:16,539 - mmdet - INFO - Epoch [1][7900/29317]	lr: 9.689e-07, eta: 4 days, 2:18:49, time: 0.494, data_time: 0.040, memory: 11094, loss_rpn_cls: 0.0478, loss_rpn_bbox: 0.0565, loss_cls: 0.2987, acc: 92.1821, loss_bbox: 0.2405, loss_mask: 0.3400, loss: 0.9836
2022-04-15 12:38:40,463 - mmdet - INFO - Epoch [1][7950/29317]	lr: 9.689e-07, eta: 4 days, 2:17:42, time: 0.479, data_time: 0.046, memory: 11094, loss_rpn_cls: 0.0487, loss_rpn_bbox: 0.0548, loss_cls: 0.2969, acc: 92.1282, loss_bbox: 0.2459, loss_mask: 0.3363, loss: 0.9827
2022-04-15 12:39:05,322 - mmdet - INFO - Exp name: vitdet_sfp_100e_fp16_coco.py
2022-04-15 12:39:05,323 - mmdet - INFO - Epoch [1][8000/29317]	lr: 9.689e-07, eta: 4 days, 2:17:58, time: 0.497, data_time: 0.038, memory: 11094, loss_rpn_cls: 0.0512, loss_rpn_bbox: 0.0606, loss_cls: 0.3109, acc: 91.7495, loss_bbox: 0.2588, loss_mask: 0.3492, loss: 1.0307
2022-04-15 12:39:29,831 - mmdet - INFO - Epoch [1][8050/29317]	lr: 9.689e-07, eta: 4 days, 2:17:43, time: 0.490, data_time: 0.038, memory: 11094, loss_rpn_cls: 0.0522, loss_rpn_bbox: 0.0589, loss_cls: 0.3027, acc: 91.9402, loss_bbox: 0.2503, loss_mask: 0.3400, loss: 1.0041
2022-04-15 12:39:54,492 - mmdet - INFO - Epoch [1][8100/29317]	lr: 9.689e-07, eta: 4 days, 2:17:41, time: 0.493, data_time: 0.036, memory: 11094, loss_rpn_cls: 0.0469, loss_rpn_bbox: 0.0584, loss_cls: 0.2939, acc: 92.0728, loss_bbox: 0.2465, loss_mask: 0.3317, loss: 0.9774
2022-04-15 12:40:19,080 - mmdet - INFO - Epoch [1][8150/29317]	lr: 9.689e-07, eta: 4 days, 2:17:33, time: 0.492, data_time: 0.041, memory: 11094, loss_rpn_cls: 0.0510, loss_rpn_bbox: 0.0614, loss_cls: 0.3031, acc: 91.9631, loss_bbox: 0.2545, loss_mask: 0.3516, loss: 1.0215
2022-04-15 12:40:43,160 - mmdet - INFO - Epoch [1][8200/29317]	lr: 9.689e-07, eta: 4 days, 2:16:39, time: 0.482, data_time: 0.035, memory: 11094, loss_rpn_cls: 0.0482, loss_rpn_bbox: 0.0567, loss_cls: 0.2935, acc: 92.2935, loss_bbox: 0.2437, loss_mask: 0.3393, loss: 0.9814
2022-04-15 12:41:07,679 - mmdet - INFO - Epoch [1][8250/29317]	lr: 9.689e-07, eta: 4 days, 2:16:24, time: 0.490, data_time: 0.036, memory: 11094, loss_rpn_cls: 0.0511, loss_rpn_bbox: 0.0599, loss_cls: 0.3079, acc: 91.8328, loss_bbox: 0.2526, loss_mask: 0.3349, loss: 1.0064
2022-04-15 12:41:31,404 - mmdet - INFO - Epoch [1][8300/29317]	lr: 9.689e-07, eta: 4 days, 2:15:00, time: 0.474, data_time: 0.039, memory: 11094, loss_rpn_cls: 0.0464, loss_rpn_bbox: 0.0525, loss_cls: 0.2808, acc: 92.5486, loss_bbox: 0.2329, loss_mask: 0.3424, loss: 0.9551
2022-04-15 12:41:55,412 - mmdet - INFO - Epoch [1][8350/29317]	lr: 9.689e-07, eta: 4 days, 2:14:01, time: 0.480, data_time: 0.031, memory: 11094, loss_rpn_cls: 0.0456, loss_rpn_bbox: 0.0531, loss_cls: 0.3023, acc: 92.2239, loss_bbox: 0.2426, loss_mask: 0.3501, loss: 0.9937
2022-04-15 12:42:19,969 - mmdet - INFO - Epoch [1][8400/29317]	lr: 9.689e-07, eta: 4 days, 2:13:49, time: 0.491, data_time: 0.034, memory: 11094, loss_rpn_cls: 0.0481, loss_rpn_bbox: 0.0561, loss_cls: 0.2911, acc: 92.3010, loss_bbox: 0.2373, loss_mask: 0.3384, loss: 0.9710
2022-04-15 12:42:44,316 - mmdet - INFO - Epoch [1][8450/29317]	lr: 9.689e-07, eta: 4 days, 2:13:20, time: 0.487, data_time: 0.038, memory: 11094, loss_rpn_cls: 0.0525, loss_rpn_bbox: 0.0578, loss_cls: 0.3111, acc: 91.7375, loss_bbox: 0.2554, loss_mask: 0.3358, loss: 1.0125
2022-04-15 12:43:08,802 - mmdet - INFO - Epoch [1][8500/29317]	lr: 9.689e-07, eta: 4 days, 2:13:03, time: 0.490, data_time: 0.037, memory: 11094, loss_rpn_cls: 0.0516, loss_rpn_bbox: 0.0581, loss_cls: 0.3011, acc: 91.9526, loss_bbox: 0.2539, loss_mask: 0.3493, loss: 1.0142
2022-04-15 12:43:33,362 - mmdet - INFO - Epoch [1][8550/29317]	lr: 9.689e-07, eta: 4 days, 2:12:52, time: 0.491, data_time: 0.042, memory: 11094, loss_rpn_cls: 0.0497, loss_rpn_bbox: 0.0557, loss_cls: 0.2983, acc: 91.9841, loss_bbox: 0.2453, loss_mask: 0.3346, loss: 0.9837
2022-04-15 12:43:58,023 - mmdet - INFO - Epoch [1][8600/29317]	lr: 9.689e-07, eta: 4 days, 2:12:48, time: 0.493, data_time: 0.041, memory: 11094, loss_rpn_cls: 0.0498, loss_rpn_bbox: 0.0615, loss_cls: 0.3229, acc: 91.4353, loss_bbox: 0.2728, loss_mask: 0.3433, loss: 1.0503
2022-04-15 12:44:22,947 - mmdet - INFO - Epoch [1][8650/29317]	lr: 9.689e-07, eta: 4 days, 2:13:07, time: 0.499, data_time: 0.032, memory: 11094, loss_rpn_cls: 0.0523, loss_rpn_bbox: 0.0582, loss_cls: 0.3042, acc: 91.9634, loss_bbox: 0.2479, loss_mask: 0.3530, loss: 1.0155
2022-04-15 12:44:47,402 - mmdet - INFO - Epoch [1][8700/29317]	lr: 9.689e-07, eta: 4 days, 2:12:47, time: 0.489, data_time: 0.035, memory: 11094, loss_rpn_cls: 0.0477, loss_rpn_bbox: 0.0548, loss_cls: 0.2879, acc: 92.4304, loss_bbox: 0.2382, loss_mask: 0.3402, loss: 0.9687
2022-04-15 12:45:12,055 - mmdet - INFO - Epoch [1][8750/29317]	lr: 9.689e-07, eta: 4 days, 2:12:42, time: 0.493, data_time: 0.042, memory: 11094, loss_rpn_cls: 0.0501, loss_rpn_bbox: 0.0576, loss_cls: 0.2943, acc: 92.2080, loss_bbox: 0.2463, loss_mask: 0.3531, loss: 1.0014
2022-04-15 12:45:36,307 - mmdet - INFO - Epoch [1][8800/29317]	lr: 9.689e-07, eta: 4 days, 2:12:05, time: 0.485, data_time: 0.034, memory: 11094, loss_rpn_cls: 0.0476, loss_rpn_bbox: 0.0566, loss_cls: 0.2936, acc: 92.1670, loss_bbox: 0.2449, loss_mask: 0.3536, loss: 0.9963
2022-04-15 12:46:00,796 - mmdet - INFO - Epoch [1][8850/29317]	lr: 9.689e-07, eta: 4 days, 2:11:47, time: 0.490, data_time: 0.036, memory: 11094, loss_rpn_cls: 0.0500, loss_rpn_bbox: 0.0574, loss_cls: 0.3011, acc: 91.9316, loss_bbox: 0.2522, loss_mask: 0.3358, loss: 0.9965
2022-04-15 12:46:25,413 - mmdet - INFO - Epoch [1][8900/29317]	lr: 9.689e-07, eta: 4 days, 2:11:39, time: 0.492, data_time: 0.036, memory: 11094, loss_rpn_cls: 0.0489, loss_rpn_bbox: 0.0575, loss_cls: 0.2985, acc: 92.0498, loss_bbox: 0.2504, loss_mask: 0.3431, loss: 0.9984
2022-04-15 12:46:49,721 - mmdet - INFO - Epoch [1][8950/29317]	lr: 9.689e-07, eta: 4 days, 2:11:06, time: 0.486, data_time: 0.032, memory: 11094, loss_rpn_cls: 0.0435, loss_rpn_bbox: 0.0545, loss_cls: 0.2869, acc: 92.4060, loss_bbox: 0.2389, loss_mask: 0.3378, loss: 0.9615
2022-04-15 12:47:14,081 - mmdet - INFO - Exp name: vitdet_sfp_100e_fp16_coco.py
2022-04-15 12:47:14,082 - mmdet - INFO - Epoch [1][9000/29317]	lr: 9.689e-07, eta: 4 days, 2:10:37, time: 0.487, data_time: 0.038, memory: 11094, loss_rpn_cls: 0.0489, loss_rpn_bbox: 0.0608, loss_cls: 0.2967, acc: 92.0322, loss_bbox: 0.2451, loss_mask: 0.3389, loss: 0.9904
2022-04-15 12:47:38,412 - mmdet - INFO - Epoch [1][9050/29317]	lr: 9.689e-07, eta: 4 days, 2:10:07, time: 0.487, data_time: 0.039, memory: 11094, loss_rpn_cls: 0.0474, loss_rpn_bbox: 0.0540, loss_cls: 0.2898, acc: 92.0991, loss_bbox: 0.2439, loss_mask: 0.3293, loss: 0.9643
2022-04-15 12:48:03,259 - mmdet - INFO - Epoch [1][9100/29317]	lr: 9.689e-07, eta: 4 days, 2:10:17, time: 0.497, data_time: 0.039, memory: 11094, loss_rpn_cls: 0.0457, loss_rpn_bbox: 0.0549, loss_cls: 0.2906, acc: 92.0203, loss_bbox: 0.2457, loss_mask: 0.3420, loss: 0.9789
2022-04-15 12:48:28,251 - mmdet - INFO - Epoch [1][9150/29317]	lr: 9.689e-07, eta: 4 days, 2:10:38, time: 0.500, data_time: 0.035, memory: 11094, loss_rpn_cls: 0.0467, loss_rpn_bbox: 0.0559, loss_cls: 0.2949, acc: 92.0989, loss_bbox: 0.2415, loss_mask: 0.3318, loss: 0.9707
2022-04-15 12:48:52,867 - mmdet - INFO - Epoch [1][9200/29317]	lr: 9.689e-07, eta: 4 days, 2:10:30, time: 0.492, data_time: 0.035, memory: 11094, loss_rpn_cls: 0.0481, loss_rpn_bbox: 0.0572, loss_cls: 0.3078, acc: 91.7263, loss_bbox: 0.2547, loss_mask: 0.3417, loss: 1.0095
2022-04-15 12:49:17,383 - mmdet - INFO - Epoch [1][9250/29317]	lr: 9.689e-07, eta: 4 days, 2:10:13, time: 0.490, data_time: 0.036, memory: 11094, loss_rpn_cls: 0.0460, loss_rpn_bbox: 0.0548, loss_cls: 0.2985, acc: 91.9456, loss_bbox: 0.2473, loss_mask: 0.3419, loss: 0.9884
2022-04-15 12:49:41,428 - mmdet - INFO - Epoch [1][9300/29317]	lr: 9.689e-07, eta: 4 days, 2:09:19, time: 0.481, data_time: 0.033, memory: 11094, loss_rpn_cls: 0.0455, loss_rpn_bbox: 0.0558, loss_cls: 0.3009, acc: 91.8020, loss_bbox: 0.2529, loss_mask: 0.3384, loss: 0.9934
2022-04-15 12:50:06,608 - mmdet - INFO - Epoch [1][9350/29317]	lr: 9.689e-07, eta: 4 days, 2:09:54, time: 0.504, data_time: 0.043, memory: 11094, loss_rpn_cls: 0.0510, loss_rpn_bbox: 0.0568, loss_cls: 0.2909, acc: 92.2236, loss_bbox: 0.2382, loss_mask: 0.3393, loss: 0.9763
2022-04-15 12:50:31,196 - mmdet - INFO - Epoch [1][9400/29317]	lr: 9.689e-07, eta: 4 days, 2:09:43, time: 0.492, data_time: 0.041, memory: 11094, loss_rpn_cls: 0.0482, loss_rpn_bbox: 0.0586, loss_cls: 0.2858, acc: 92.3462, loss_bbox: 0.2378, loss_mask: 0.3418, loss: 0.9722
2022-04-15 12:50:55,533 - mmdet - INFO - Epoch [1][9450/29317]	lr: 9.689e-07, eta: 4 days, 2:09:12, time: 0.487, data_time: 0.037, memory: 11094, loss_rpn_cls: 0.0464, loss_rpn_bbox: 0.0537, loss_cls: 0.2808, acc: 92.4092, loss_bbox: 0.2322, loss_mask: 0.3323, loss: 0.9454
2022-04-15 12:51:20,423 - mmdet - INFO - Epoch [1][9500/29317]	lr: 9.689e-07, eta: 4 days, 2:09:22, time: 0.498, data_time: 0.035, memory: 11094, loss_rpn_cls: 0.0488, loss_rpn_bbox: 0.0563, loss_cls: 0.2987, acc: 91.9946, loss_bbox: 0.2455, loss_mask: 0.3337, loss: 0.9831
2022-04-15 12:51:44,956 - mmdet - INFO - Epoch [1][9550/29317]	lr: 9.689e-07, eta: 4 days, 2:09:07, time: 0.491, data_time: 0.034, memory: 11094, loss_rpn_cls: 0.0460, loss_rpn_bbox: 0.0567, loss_cls: 0.2986, acc: 91.7910, loss_bbox: 0.2530, loss_mask: 0.3315, loss: 0.9859
2022-04-15 12:52:09,565 - mmdet - INFO - Epoch [1][9600/29317]	lr: 9.689e-07, eta: 4 days, 2:08:56, time: 0.492, data_time: 0.039, memory: 11094, loss_rpn_cls: 0.0485, loss_rpn_bbox: 0.0613, loss_cls: 0.3055, acc: 91.8540, loss_bbox: 0.2509, loss_mask: 0.3406, loss: 1.0068
2022-04-15 12:52:33,715 - mmdet - INFO - Epoch [1][9650/29317]	lr: 9.689e-07, eta: 4 days, 2:08:11, time: 0.483, data_time: 0.039, memory: 11094, loss_rpn_cls: 0.0480, loss_rpn_bbox: 0.0555, loss_cls: 0.2881, acc: 91.9888, loss_bbox: 0.2425, loss_mask: 0.3294, loss: 0.9634
2022-04-15 12:52:58,909 - mmdet - INFO - Epoch [1][9700/29317]	lr: 9.689e-07, eta: 4 days, 2:08:44, time: 0.504, data_time: 0.044, memory: 11094, loss_rpn_cls: 0.0488, loss_rpn_bbox: 0.0603, loss_cls: 0.3123, acc: 91.4680, loss_bbox: 0.2622, loss_mask: 0.3357, loss: 1.0193
2022-04-15 12:53:22,783 - mmdet - INFO - Epoch [1][9750/29317]	lr: 9.689e-07, eta: 4 days, 2:07:39, time: 0.478, data_time: 0.036, memory: 11094, loss_rpn_cls: 0.0423, loss_rpn_bbox: 0.0525, loss_cls: 0.2764, acc: 92.4788, loss_bbox: 0.2343, loss_mask: 0.3272, loss: 0.9327
2022-04-15 12:53:48,047 - mmdet - INFO - Epoch [1][9800/29317]	lr: 9.689e-07, eta: 4 days, 2:08:16, time: 0.505, data_time: 0.040, memory: 11094, loss_rpn_cls: 0.0442, loss_rpn_bbox: 0.0564, loss_cls: 0.2966, acc: 92.0325, loss_bbox: 0.2447, loss_mask: 0.3343, loss: 0.9763
2022-04-15 12:54:12,491 - mmdet - INFO - Epoch [1][9850/29317]	lr: 9.689e-07, eta: 4 days, 2:07:53, time: 0.489, data_time: 0.036, memory: 11094, loss_rpn_cls: 0.0512, loss_rpn_bbox: 0.0594, loss_cls: 0.2992, acc: 91.8606, loss_bbox: 0.2491, loss_mask: 0.3330, loss: 0.9919
2022-04-15 12:54:37,256 - mmdet - INFO - Epoch [1][9900/29317]	lr: 9.689e-07, eta: 4 days, 2:07:53, time: 0.495, data_time: 0.039, memory: 11094, loss_rpn_cls: 0.0493, loss_rpn_bbox: 0.0611, loss_cls: 0.3154, acc: 91.4346, loss_bbox: 0.2621, loss_mask: 0.3419, loss: 1.0298
2022-04-15 12:55:01,909 - mmdet - INFO - Epoch [1][9950/29317]	lr: 9.689e-07, eta: 4 days, 2:07:45, time: 0.493, data_time: 0.040, memory: 11094, loss_rpn_cls: 0.0517, loss_rpn_bbox: 0.0598, loss_cls: 0.2795, acc: 92.4600, loss_bbox: 0.2388, loss_mask: 0.3458, loss: 0.9756
2022-04-15 12:55:26,640 - mmdet - INFO - Exp name: vitdet_sfp_100e_fp16_coco.py
2022-04-15 12:55:26,640 - mmdet - INFO - Epoch [1][10000/29317]	lr: 9.689e-07, eta: 4 days, 2:07:42, time: 0.495, data_time: 0.039, memory: 11094, loss_rpn_cls: 0.0484, loss_rpn_bbox: 0.0581, loss_cls: 0.2898, acc: 92.0913, loss_bbox: 0.2462, loss_mask: 0.3376, loss: 0.9800
2022-04-15 12:55:51,678 - mmdet - INFO - Epoch [1][10050/29317]	lr: 9.689e-07, eta: 4 days, 2:08:01, time: 0.501, data_time: 0.036, memory: 11094, loss_rpn_cls: 0.0444, loss_rpn_bbox: 0.0556, loss_cls: 0.2877, acc: 92.1317, loss_bbox: 0.2477, loss_mask: 0.3360, loss: 0.9714
2022-04-15 12:56:16,515 - mmdet - INFO - Epoch [1][10100/29317]	lr: 9.689e-07, eta: 4 days, 2:08:04, time: 0.496, data_time: 0.040, memory: 11094, loss_rpn_cls: 0.0435, loss_rpn_bbox: 0.0523, loss_cls: 0.2854, acc: 92.2886, loss_bbox: 0.2342, loss_mask: 0.3297, loss: 0.9451
2022-04-15 12:56:41,112 - mmdet - INFO - Epoch [1][10150/29317]	lr: 9.689e-07, eta: 4 days, 2:07:52, time: 0.492, data_time: 0.039, memory: 11094, loss_rpn_cls: 0.0457, loss_rpn_bbox: 0.0576, loss_cls: 0.2895, acc: 91.9551, loss_bbox: 0.2486, loss_mask: 0.3319, loss: 0.9733
2022-04-15 12:57:05,439 - mmdet - INFO - Epoch [1][10200/29317]	lr: 9.689e-07, eta: 4 days, 2:07:20, time: 0.487, data_time: 0.042, memory: 11094, loss_rpn_cls: 0.0446, loss_rpn_bbox: 0.0548, loss_cls: 0.2810, acc: 92.2520, loss_bbox: 0.2438, loss_mask: 0.3231, loss: 0.9474
2022-04-15 12:57:29,776 - mmdet - INFO - Epoch [1][10250/29317]	lr: 9.689e-07, eta: 4 days, 2:06:48, time: 0.487, data_time: 0.042, memory: 11094, loss_rpn_cls: 0.0432, loss_rpn_bbox: 0.0525, loss_cls: 0.2837, acc: 92.2886, loss_bbox: 0.2429, loss_mask: 0.3284, loss: 0.9507
2022-04-15 12:57:54,422 - mmdet - INFO - Epoch [1][10300/29317]	lr: 9.689e-07, eta: 4 days, 2:06:38, time: 0.493, data_time: 0.034, memory: 11094, loss_rpn_cls: 0.0455, loss_rpn_bbox: 0.0554, loss_cls: 0.2791, acc: 92.4563, loss_bbox: 0.2372, loss_mask: 0.3387, loss: 0.9560
2022-04-15 12:58:19,253 - mmdet - INFO - Epoch [1][10350/29317]	lr: 9.689e-07, eta: 4 days, 2:06:41, time: 0.497, data_time: 0.041, memory: 11094, loss_rpn_cls: 0.0446, loss_rpn_bbox: 0.0584, loss_cls: 0.3108, acc: 91.4983, loss_bbox: 0.2650, loss_mask: 0.3360, loss: 1.0149
2022-04-15 12:58:43,337 - mmdet - INFO - Epoch [1][10400/29317]	lr: 9.689e-07, eta: 4 days, 2:05:52, time: 0.482, data_time: 0.040, memory: 11094, loss_rpn_cls: 0.0451, loss_rpn_bbox: 0.0524, loss_cls: 0.2891, acc: 92.1196, loss_bbox: 0.2381, loss_mask: 0.3268, loss: 0.9516
2022-04-15 12:59:07,776 - mmdet - INFO - Epoch [1][10450/29317]	lr: 9.689e-07, eta: 4 days, 2:05:28, time: 0.489, data_time: 0.043, memory: 11094, loss_rpn_cls: 0.0476, loss_rpn_bbox: 0.0567, loss_cls: 0.2886, acc: 92.0654, loss_bbox: 0.2482, loss_mask: 0.3369, loss: 0.9779
2022-04-15 12:59:32,943 - mmdet - INFO - Epoch [1][10500/29317]	lr: 9.689e-07, eta: 4 days, 2:05:52, time: 0.503, data_time: 0.035, memory: 11094, loss_rpn_cls: 0.0505, loss_rpn_bbox: 0.0566, loss_cls: 0.2875, acc: 91.8870, loss_bbox: 0.2516, loss_mask: 0.3326, loss: 0.9789
2022-04-15 12:59:57,735 - mmdet - INFO - Epoch [1][10550/29317]	lr: 9.689e-07, eta: 4 days, 2:05:53, time: 0.496, data_time: 0.037, memory: 11094, loss_rpn_cls: 0.0480, loss_rpn_bbox: 0.0553, loss_cls: 0.2902, acc: 91.9751, loss_bbox: 0.2484, loss_mask: 0.3316, loss: 0.9735
2022-04-15 13:00:22,674 - mmdet - INFO - Epoch [1][10600/29317]	lr: 9.689e-07, eta: 4 days, 2:06:02, time: 0.499, data_time: 0.041, memory: 11094, loss_rpn_cls: 0.0475, loss_rpn_bbox: 0.0547, loss_cls: 0.2892, acc: 92.2358, loss_bbox: 0.2444, loss_mask: 0.3391, loss: 0.9749
2022-04-15 13:00:47,535 - mmdet - INFO - Epoch [1][10650/29317]	lr: 9.689e-07, eta: 4 days, 2:06:06, time: 0.497, data_time: 0.041, memory: 11094, loss_rpn_cls: 0.0462, loss_rpn_bbox: 0.0558, loss_cls: 0.2924, acc: 91.9441, loss_bbox: 0.2459, loss_mask: 0.3286, loss: 0.9690
2022-04-15 13:01:12,160 - mmdet - INFO - Epoch [1][10700/29317]	lr: 9.689e-07, eta: 4 days, 2:05:53, time: 0.492, data_time: 0.037, memory: 11094, loss_rpn_cls: 0.0475, loss_rpn_bbox: 0.0563, loss_cls: 0.2860, acc: 92.1846, loss_bbox: 0.2401, loss_mask: 0.3403, loss: 0.9702
2022-04-15 13:01:36,329 - mmdet - INFO - Epoch [1][10750/29317]	lr: 9.689e-07, eta: 4 days, 2:05:10, time: 0.483, data_time: 0.037, memory: 11094, loss_rpn_cls: 0.0469, loss_rpn_bbox: 0.0514, loss_cls: 0.2911, acc: 92.0837, loss_bbox: 0.2401, loss_mask: 0.3297, loss: 0.9592
2022-04-15 13:02:01,027 - mmdet - INFO - Epoch [1][10800/29317]	lr: 9.689e-07, eta: 4 days, 2:05:01, time: 0.493, data_time: 0.034, memory: 11094, loss_rpn_cls: 0.0436, loss_rpn_bbox: 0.0586, loss_cls: 0.2867, acc: 92.1897, loss_bbox: 0.2386, loss_mask: 0.3244, loss: 0.9519
2022-04-15 13:02:26,145 - mmdet - INFO - Epoch [1][10850/29317]	lr: 9.689e-07, eta: 4 days, 2:05:22, time: 0.503, data_time: 0.042, memory: 11094, loss_rpn_cls: 0.0456, loss_rpn_bbox: 0.0570, loss_cls: 0.2947, acc: 91.7488, loss_bbox: 0.2539, loss_mask: 0.3279, loss: 0.9791
2022-04-15 13:02:50,956 - mmdet - INFO - Epoch [1][10900/29317]	lr: 9.689e-07, eta: 4 days, 2:05:21, time: 0.496, data_time: 0.034, memory: 11094, loss_rpn_cls: 0.0460, loss_rpn_bbox: 0.0539, loss_cls: 0.2859, acc: 92.2190, loss_bbox: 0.2371, loss_mask: 0.3265, loss: 0.9494
2022-04-15 13:03:15,947 - mmdet - INFO - Epoch [1][10950/29317]	lr: 9.689e-07, eta: 4 days, 2:05:32, time: 0.500, data_time: 0.038, memory: 11094, loss_rpn_cls: 0.0454, loss_rpn_bbox: 0.0540, loss_cls: 0.2764, acc: 92.3176, loss_bbox: 0.2378, loss_mask: 0.3223, loss: 0.9358
2022-04-15 13:03:41,000 - mmdet - INFO - Exp name: vitdet_sfp_100e_fp16_coco.py
2022-04-15 13:03:41,000 - mmdet - INFO - Epoch [1][11000/29317]	lr: 9.689e-07, eta: 4 days, 2:05:47, time: 0.501, data_time: 0.034, memory: 11094, loss_rpn_cls: 0.0477, loss_rpn_bbox: 0.0577, loss_cls: 0.2883, acc: 91.9976, loss_bbox: 0.2450, loss_mask: 0.3218, loss: 0.9604
2022-04-15 13:04:05,517 - mmdet - INFO - Epoch [1][11050/29317]	lr: 9.689e-07, eta: 4 days, 2:05:26, time: 0.490, data_time: 0.039, memory: 11094, loss_rpn_cls: 0.0413, loss_rpn_bbox: 0.0558, loss_cls: 0.2870, acc: 92.1282, loss_bbox: 0.2451, loss_mask: 0.3296, loss: 0.9587
2022-04-15 13:04:30,080 - mmdet - INFO - Epoch [1][11100/29317]	lr: 9.689e-07, eta: 4 days, 2:05:07, time: 0.491, data_time: 0.041, memory: 11094, loss_rpn_cls: 0.0461, loss_rpn_bbox: 0.0552, loss_cls: 0.2945, acc: 91.8953, loss_bbox: 0.2460, loss_mask: 0.3348, loss: 0.9767
2022-04-15 13:04:55,025 - mmdet - INFO - Epoch [1][11150/29317]	lr: 9.689e-07, eta: 4 days, 2:05:16, time: 0.499, data_time: 0.036, memory: 11094, loss_rpn_cls: 0.0455, loss_rpn_bbox: 0.0562, loss_cls: 0.2888, acc: 92.1450, loss_bbox: 0.2399, loss_mask: 0.3279, loss: 0.9582
2022-04-15 13:05:20,461 - mmdet - INFO - Epoch [1][11200/29317]	lr: 9.689e-07, eta: 4 days, 2:05:53, time: 0.508, data_time: 0.037, memory: 11094, loss_rpn_cls: 0.0432, loss_rpn_bbox: 0.0541, loss_cls: 0.2895, acc: 92.0713, loss_bbox: 0.2438, loss_mask: 0.3340, loss: 0.9645
2022-04-15 13:05:44,765 - mmdet - INFO - Epoch [1][11250/29317]	lr: 9.689e-07, eta: 4 days, 2:05:19, time: 0.487, data_time: 0.038, memory: 11094, loss_rpn_cls: 0.0449, loss_rpn_bbox: 0.0539, loss_cls: 0.2704, acc: 92.4976, loss_bbox: 0.2327, loss_mask: 0.3263, loss: 0.9281
2022-04-15 13:06:09,089 - mmdet - INFO - Epoch [1][11300/29317]	lr: 9.689e-07, eta: 4 days, 2:04:45, time: 0.486, data_time: 0.036, memory: 11094, loss_rpn_cls: 0.0482, loss_rpn_bbox: 0.0557, loss_cls: 0.2935, acc: 91.9280, loss_bbox: 0.2453, loss_mask: 0.3292, loss: 0.9719
2022-04-15 13:06:33,466 - mmdet - INFO - Epoch [1][11350/29317]	lr: 9.689e-07, eta: 4 days, 2:04:16, time: 0.488, data_time: 0.037, memory: 11094, loss_rpn_cls: 0.0491, loss_rpn_bbox: 0.0578, loss_cls: 0.2956, acc: 91.7786, loss_bbox: 0.2481, loss_mask: 0.3306, loss: 0.9812
2022-04-15 13:06:58,096 - mmdet - INFO - Epoch [1][11400/29317]	lr: 9.689e-07, eta: 4 days, 2:04:00, time: 0.492, data_time: 0.037, memory: 11094, loss_rpn_cls: 0.0445, loss_rpn_bbox: 0.0545, loss_cls: 0.2857, acc: 92.2026, loss_bbox: 0.2417, loss_mask: 0.3382, loss: 0.9645
2022-04-15 13:07:22,742 - mmdet - INFO - Epoch [1][11450/29317]	lr: 9.689e-07, eta: 4 days, 2:03:48, time: 0.493, data_time: 0.035, memory: 11094, loss_rpn_cls: 0.0446, loss_rpn_bbox: 0.0505, loss_cls: 0.2807, acc: 92.2876, loss_bbox: 0.2394, loss_mask: 0.3236, loss: 0.9387
2022-04-15 13:07:46,931 - mmdet - INFO - Epoch [1][11500/29317]	lr: 9.689e-07, eta: 4 days, 2:03:07, time: 0.484, data_time: 0.035, memory: 11094, loss_rpn_cls: 0.0436, loss_rpn_bbox: 0.0520, loss_cls: 0.2700, acc: 92.5603, loss_bbox: 0.2277, loss_mask: 0.3251, loss: 0.9185
2022-04-15 13:08:11,277 - mmdet - INFO - Epoch [1][11550/29317]	lr: 9.689e-07, eta: 4 days, 2:02:35, time: 0.487, data_time: 0.038, memory: 11094, loss_rpn_cls: 0.0420, loss_rpn_bbox: 0.0513, loss_cls: 0.2666, acc: 92.4932, loss_bbox: 0.2315, loss_mask: 0.3255, loss: 0.9169
2022-04-15 13:08:35,710 - mmdet - INFO - Epoch [1][11600/29317]	lr: 9.689e-07, eta: 4 days, 2:02:08, time: 0.489, data_time: 0.033, memory: 11094, loss_rpn_cls: 0.0400, loss_rpn_bbox: 0.0545, loss_cls: 0.2816, acc: 92.1677, loss_bbox: 0.2456, loss_mask: 0.3256, loss: 0.9473
2022-04-15 13:09:00,887 - mmdet - INFO - Epoch [1][11650/29317]	lr: 9.689e-07, eta: 4 days, 2:02:28, time: 0.504, data_time: 0.041, memory: 11094, loss_rpn_cls: 0.0450, loss_rpn_bbox: 0.0562, loss_cls: 0.2861, acc: 92.0442, loss_bbox: 0.2495, loss_mask: 0.3245, loss: 0.9613
2022-04-15 13:09:25,272 - mmdet - INFO - Epoch [1][11700/29317]	lr: 9.689e-07, eta: 4 days, 2:01:58, time: 0.488, data_time: 0.038, memory: 11094, loss_rpn_cls: 0.0421, loss_rpn_bbox: 0.0508, loss_cls: 0.2838, acc: 92.3372, loss_bbox: 0.2385, loss_mask: 0.3309, loss: 0.9462
2022-04-15 13:09:49,503 - mmdet - INFO - Epoch [1][11750/29317]	lr: 9.689e-07, eta: 4 days, 2:01:19, time: 0.485, data_time: 0.038, memory: 11094, loss_rpn_cls: 0.0433, loss_rpn_bbox: 0.0498, loss_cls: 0.2838, acc: 92.2722, loss_bbox: 0.2352, loss_mask: 0.3249, loss: 0.9369
2022-04-15 13:10:14,067 - mmdet - INFO - Epoch [1][11800/29317]	lr: 9.689e-07, eta: 4 days, 2:01:01, time: 0.491, data_time: 0.041, memory: 11094, loss_rpn_cls: 0.0441, loss_rpn_bbox: 0.0552, loss_cls: 0.2958, acc: 91.9197, loss_bbox: 0.2506, loss_mask: 0.3287, loss: 0.9743
2022-04-15 13:10:38,172 - mmdet - INFO - Epoch [1][11850/29317]	lr: 9.689e-07, eta: 4 days, 2:00:14, time: 0.482, data_time: 0.036, memory: 11094, loss_rpn_cls: 0.0445, loss_rpn_bbox: 0.0546, loss_cls: 0.2786, acc: 92.3726, loss_bbox: 0.2346, loss_mask: 0.3200, loss: 0.9322
2022-04-15 13:11:02,823 - mmdet - INFO - Epoch [1][11900/29317]	lr: 9.689e-07, eta: 4 days, 2:00:01, time: 0.493, data_time: 0.037, memory: 11094, loss_rpn_cls: 0.0448, loss_rpn_bbox: 0.0580, loss_cls: 0.2805, acc: 92.0745, loss_bbox: 0.2423, loss_mask: 0.3349, loss: 0.9604
2022-04-15 13:11:27,228 - mmdet - INFO - Epoch [1][11950/29317]	lr: 9.689e-07, eta: 4 days, 1:59:33, time: 0.488, data_time: 0.034, memory: 11094, loss_rpn_cls: 0.0443, loss_rpn_bbox: 0.0543, loss_cls: 0.2837, acc: 92.1877, loss_bbox: 0.2401, loss_mask: 0.3263, loss: 0.9486
2022-04-15 13:11:51,965 - mmdet - INFO - Exp name: vitdet_sfp_100e_fp16_coco.py
2022-04-15 13:11:51,965 - mmdet - INFO - Epoch [1][12000/29317]	lr: 9.689e-07, eta: 4 days, 1:59:25, time: 0.495, data_time: 0.034, memory: 11094, loss_rpn_cls: 0.0451, loss_rpn_bbox: 0.0567, loss_cls: 0.2954, acc: 91.6743, loss_bbox: 0.2551, loss_mask: 0.3307, loss: 0.9830
2022-04-15 13:12:16,053 - mmdet - INFO - Epoch [1][12050/29317]	lr: 9.689e-07, eta: 4 days, 1:58:38, time: 0.482, data_time: 0.036, memory: 11094, loss_rpn_cls: 0.0425, loss_rpn_bbox: 0.0559, loss_cls: 0.2896, acc: 92.2129, loss_bbox: 0.2389, loss_mask: 0.3327, loss: 0.9596
2022-04-15 13:12:41,432 - mmdet - INFO - Epoch [1][12100/29317]	lr: 9.689e-07, eta: 4 days, 1:59:08, time: 0.508, data_time: 0.046, memory: 11094, loss_rpn_cls: 0.0469, loss_rpn_bbox: 0.0566, loss_cls: 0.2885, acc: 91.9358, loss_bbox: 0.2458, loss_mask: 0.3308, loss: 0.9686
2022-04-15 13:13:06,275 - mmdet - INFO - Epoch [1][12150/29317]	lr: 9.689e-07, eta: 4 days, 1:59:06, time: 0.497, data_time: 0.041, memory: 11094, loss_rpn_cls: 0.0432, loss_rpn_bbox: 0.0545, loss_cls: 0.2775, acc: 92.3342, loss_bbox: 0.2410, loss_mask: 0.3347, loss: 0.9509
2022-04-15 13:13:30,978 - mmdet - INFO - Epoch [1][12200/29317]	lr: 9.689e-07, eta: 4 days, 1:58:55, time: 0.494, data_time: 0.035, memory: 11094, loss_rpn_cls: 0.0432, loss_rpn_bbox: 0.0550, loss_cls: 0.2879, acc: 91.9805, loss_bbox: 0.2458, loss_mask: 0.3255, loss: 0.9574
2022-04-15 13:13:55,769 - mmdet - INFO - Epoch [1][12250/29317]	lr: 9.689e-07, eta: 4 days, 1:58:49, time: 0.496, data_time: 0.035, memory: 11094, loss_rpn_cls: 0.0431, loss_rpn_bbox: 0.0544, loss_cls: 0.2895, acc: 92.0144, loss_bbox: 0.2449, loss_mask: 0.3271, loss: 0.9589
2022-04-15 13:14:20,249 - mmdet - INFO - Epoch [1][12300/29317]	lr: 9.689e-07, eta: 4 days, 1:58:25, time: 0.490, data_time: 0.039, memory: 11094, loss_rpn_cls: 0.0440, loss_rpn_bbox: 0.0568, loss_cls: 0.2790, acc: 92.1428, loss_bbox: 0.2444, loss_mask: 0.3293, loss: 0.9534
2022-04-15 13:14:44,797 - mmdet - INFO - Epoch [1][12350/29317]	lr: 9.689e-07, eta: 4 days, 1:58:05, time: 0.491, data_time: 0.037, memory: 11094, loss_rpn_cls: 0.0465, loss_rpn_bbox: 0.0550, loss_cls: 0.2795, acc: 92.3022, loss_bbox: 0.2370, loss_mask: 0.3202, loss: 0.9381
2022-04-15 13:15:09,441 - mmdet - INFO - Epoch [1][12400/29317]	lr: 9.689e-07, eta: 4 days, 1:57:50, time: 0.493, data_time: 0.040, memory: 11094, loss_rpn_cls: 0.0475, loss_rpn_bbox: 0.0563, loss_cls: 0.2866, acc: 92.1926, loss_bbox: 0.2401, loss_mask: 0.3294, loss: 0.9599
2022-04-15 13:15:33,594 - mmdet - INFO - Epoch [1][12450/29317]	lr: 9.689e-07, eta: 4 days, 1:57:07, time: 0.483, data_time: 0.035, memory: 11094, loss_rpn_cls: 0.0433, loss_rpn_bbox: 0.0530, loss_cls: 0.2757, acc: 92.3132, loss_bbox: 0.2358, loss_mask: 0.3235, loss: 0.9313
2022-04-15 13:15:57,567 - mmdet - INFO - Epoch [1][12500/29317]	lr: 9.689e-07, eta: 4 days, 1:56:14, time: 0.479, data_time: 0.037, memory: 11094, loss_rpn_cls: 0.0442, loss_rpn_bbox: 0.0541, loss_cls: 0.2735, acc: 92.4797, loss_bbox: 0.2308, loss_mask: 0.3291, loss: 0.9317
2022-04-15 13:16:22,067 - mmdet - INFO - Epoch [1][12550/29317]	lr: 9.689e-07, eta: 4 days, 1:55:51, time: 0.490, data_time: 0.041, memory: 11094, loss_rpn_cls: 0.0429, loss_rpn_bbox: 0.0529, loss_cls: 0.2899, acc: 92.0146, loss_bbox: 0.2403, loss_mask: 0.3259, loss: 0.9519
2022-04-15 13:16:46,425 - mmdet - INFO - Epoch [1][12600/29317]	lr: 9.689e-07, eta: 4 days, 1:55:20, time: 0.487, data_time: 0.037, memory: 11094, loss_rpn_cls: 0.0435, loss_rpn_bbox: 0.0524, loss_cls: 0.2757, acc: 92.5427, loss_bbox: 0.2321, loss_mask: 0.3297, loss: 0.9335
2022-04-15 13:17:11,355 - mmdet - INFO - Epoch [1][12650/29317]	lr: 9.689e-07, eta: 4 days, 1:55:22, time: 0.499, data_time: 0.040, memory: 11094, loss_rpn_cls: 0.0456, loss_rpn_bbox: 0.0538, loss_cls: 0.2743, acc: 92.4016, loss_bbox: 0.2317, loss_mask: 0.3229, loss: 0.9283
2022-04-15 13:17:35,711 - mmdet - INFO - Epoch [1][12700/29317]	lr: 9.689e-07, eta: 4 days, 1:54:51, time: 0.487, data_time: 0.039, memory: 11094, loss_rpn_cls: 0.0450, loss_rpn_bbox: 0.0548, loss_cls: 0.2782, acc: 92.2046, loss_bbox: 0.2375, loss_mask: 0.3300, loss: 0.9455
2022-04-15 13:18:00,236 - mmdet - INFO - Epoch [1][12750/29317]	lr: 9.689e-07, eta: 4 days, 1:54:30, time: 0.490, data_time: 0.033, memory: 11094, loss_rpn_cls: 0.0448, loss_rpn_bbox: 0.0545, loss_cls: 0.2832, acc: 92.1208, loss_bbox: 0.2427, loss_mask: 0.3351, loss: 0.9603
2022-04-15 13:18:24,086 - mmdet - INFO - Epoch [1][12800/29317]	lr: 9.689e-07, eta: 4 days, 1:53:30, time: 0.477, data_time: 0.035, memory: 11094, loss_rpn_cls: 0.0420, loss_rpn_bbox: 0.0536, loss_cls: 0.2808, acc: 92.2483, loss_bbox: 0.2351, loss_mask: 0.3252, loss: 0.9367
2022-04-15 13:18:49,436 - mmdet - INFO - Epoch [1][12850/29317]	lr: 9.689e-07, eta: 4 days, 1:53:55, time: 0.507, data_time: 0.040, memory: 11094, loss_rpn_cls: 0.0437, loss_rpn_bbox: 0.0577, loss_cls: 0.2798, acc: 92.1675, loss_bbox: 0.2437, loss_mask: 0.3279, loss: 0.9528
2022-04-15 13:19:13,812 - mmdet - INFO - Epoch [1][12900/29317]	lr: 9.689e-07, eta: 4 days, 1:53:25, time: 0.487, data_time: 0.041, memory: 11094, loss_rpn_cls: 0.0433, loss_rpn_bbox: 0.0559, loss_cls: 0.2791, acc: 92.2144, loss_bbox: 0.2401, loss_mask: 0.3168, loss: 0.9353
2022-04-15 13:19:38,077 - mmdet - INFO - Epoch [1][12950/29317]	lr: 9.689e-07, eta: 4 days, 1:52:49, time: 0.485, data_time: 0.037, memory: 11094, loss_rpn_cls: 0.0401, loss_rpn_bbox: 0.0530, loss_cls: 0.2694, acc: 92.4299, loss_bbox: 0.2327, loss_mask: 0.3302, loss: 0.9255
2022-04-15 13:20:02,775 - mmdet - INFO - Exp name: vitdet_sfp_100e_fp16_coco.py
2022-04-15 13:20:02,775 - mmdet - INFO - Epoch [1][13000/29317]	lr: 9.689e-07, eta: 4 days, 1:52:37, time: 0.494, data_time: 0.040, memory: 11094, loss_rpn_cls: 0.0431, loss_rpn_bbox: 0.0534, loss_cls: 0.2805, acc: 92.0818, loss_bbox: 0.2421, loss_mask: 0.3238, loss: 0.9429
2022-04-15 13:20:27,175 - mmdet - INFO - Epoch [1][13050/29317]	lr: 9.689e-07, eta: 4 days, 1:52:09, time: 0.488, data_time: 0.031, memory: 11094, loss_rpn_cls: 0.0436, loss_rpn_bbox: 0.0535, loss_cls: 0.2619, acc: 92.7581, loss_bbox: 0.2263, loss_mask: 0.3259, loss: 0.9111
2022-04-15 13:20:51,324 - mmdet - INFO - Epoch [1][13100/29317]	lr: 9.689e-07, eta: 4 days, 1:51:27, time: 0.483, data_time: 0.034, memory: 11094, loss_rpn_cls: 0.0392, loss_rpn_bbox: 0.0496, loss_cls: 0.2695, acc: 92.5112, loss_bbox: 0.2329, loss_mask: 0.3238, loss: 0.9150
2022-04-15 13:21:15,968 - mmdet - INFO - Epoch [1][13150/29317]	lr: 9.689e-07, eta: 4 days, 1:51:12, time: 0.493, data_time: 0.033, memory: 11094, loss_rpn_cls: 0.0414, loss_rpn_bbox: 0.0533, loss_cls: 0.2888, acc: 91.8826, loss_bbox: 0.2483, loss_mask: 0.3207, loss: 0.9525
2022-04-15 13:21:40,144 - mmdet - INFO - Epoch [1][13200/29317]	lr: 9.689e-07, eta: 4 days, 1:50:30, time: 0.483, data_time: 0.041, memory: 11094, loss_rpn_cls: 0.0438, loss_rpn_bbox: 0.0549, loss_cls: 0.2751, acc: 92.3103, loss_bbox: 0.2397, loss_mask: 0.3208, loss: 0.9344
2022-04-15 13:22:04,529 - mmdet - INFO - Epoch [1][13250/29317]	lr: 9.689e-07, eta: 4 days, 1:50:02, time: 0.488, data_time: 0.043, memory: 11094, loss_rpn_cls: 0.0457, loss_rpn_bbox: 0.0588, loss_cls: 0.2894, acc: 91.9297, loss_bbox: 0.2514, loss_mask: 0.3326, loss: 0.9779
2022-04-15 13:22:29,342 - mmdet - INFO - Epoch [1][13300/29317]	lr: 9.689e-07, eta: 4 days, 1:49:56, time: 0.496, data_time: 0.042, memory: 11094, loss_rpn_cls: 0.0423, loss_rpn_bbox: 0.0544, loss_cls: 0.2814, acc: 92.0525, loss_bbox: 0.2485, loss_mask: 0.3334, loss: 0.9600
2022-04-15 13:22:53,343 - mmdet - INFO - Epoch [1][13350/29317]	lr: 9.689e-07, eta: 4 days, 1:49:06, time: 0.480, data_time: 0.046, memory: 11094, loss_rpn_cls: 0.0452, loss_rpn_bbox: 0.0531, loss_cls: 0.2724, acc: 92.4365, loss_bbox: 0.2347, loss_mask: 0.3247, loss: 0.9301
2022-04-15 13:23:17,776 - mmdet - INFO - Epoch [1][13400/29317]	lr: 9.689e-07, eta: 4 days, 1:48:40, time: 0.489, data_time: 0.040, memory: 11094, loss_rpn_cls: 0.0432, loss_rpn_bbox: 0.0529, loss_cls: 0.2811, acc: 92.1804, loss_bbox: 0.2425, loss_mask: 0.3320, loss: 0.9517
2022-04-15 13:23:42,236 - mmdet - INFO - Epoch [1][13450/29317]	lr: 9.689e-07, eta: 4 days, 1:48:15, time: 0.489, data_time: 0.034, memory: 11094, loss_rpn_cls: 0.0454, loss_rpn_bbox: 0.0569, loss_cls: 0.2918, acc: 91.7451, loss_bbox: 0.2531, loss_mask: 0.3233, loss: 0.9706
2022-04-15 13:24:07,052 - mmdet - INFO - Epoch [1][13500/29317]	lr: 9.689e-07, eta: 4 days, 1:48:09, time: 0.496, data_time: 0.038, memory: 11094, loss_rpn_cls: 0.0417, loss_rpn_bbox: 0.0530, loss_cls: 0.2877, acc: 91.8088, loss_bbox: 0.2472, loss_mask: 0.3207, loss: 0.9503
2022-04-15 13:24:31,112 - mmdet - INFO - Epoch [1][13550/29317]	lr: 9.689e-07, eta: 4 days, 1:47:23, time: 0.481, data_time: 0.040, memory: 11094, loss_rpn_cls: 0.0449, loss_rpn_bbox: 0.0564, loss_cls: 0.2765, acc: 92.2295, loss_bbox: 0.2428, loss_mask: 0.3172, loss: 0.9379
2022-04-15 13:24:55,940 - mmdet - INFO - Epoch [1][13600/29317]	lr: 9.689e-07, eta: 4 days, 1:47:17, time: 0.497, data_time: 0.045, memory: 11094, loss_rpn_cls: 0.0441, loss_rpn_bbox: 0.0558, loss_cls: 0.2804, acc: 92.1873, loss_bbox: 0.2416, loss_mask: 0.3232, loss: 0.9451
2022-04-15 13:25:20,412 - mmdet - INFO - Epoch [1][13650/29317]	lr: 9.689e-07, eta: 4 days, 1:46:53, time: 0.489, data_time: 0.033, memory: 11094, loss_rpn_cls: 0.0407, loss_rpn_bbox: 0.0549, loss_cls: 0.2782, acc: 92.1411, loss_bbox: 0.2453, loss_mask: 0.3202, loss: 0.9393
2022-04-15 13:25:44,307 - mmdet - INFO - Epoch [1][13700/29317]	lr: 9.689e-07, eta: 4 days, 1:45:58, time: 0.478, data_time: 0.033, memory: 11094, loss_rpn_cls: 0.0405, loss_rpn_bbox: 0.0539, loss_cls: 0.2788, acc: 92.1450, loss_bbox: 0.2431, loss_mask: 0.3167, loss: 0.9329
2022-04-15 13:26:08,107 - mmdet - INFO - Epoch [1][13750/29317]	lr: 9.689e-07, eta: 4 days, 1:44:59, time: 0.476, data_time: 0.039, memory: 11094, loss_rpn_cls: 0.0402, loss_rpn_bbox: 0.0497, loss_cls: 0.2644, acc: 92.6335, loss_bbox: 0.2231, loss_mask: 0.3197, loss: 0.8971
2022-04-15 13:26:32,680 - mmdet - INFO - Epoch [1][13800/29317]	lr: 9.689e-07, eta: 4 days, 1:44:39, time: 0.491, data_time: 0.034, memory: 11094, loss_rpn_cls: 0.0393, loss_rpn_bbox: 0.0534, loss_cls: 0.2690, acc: 92.3904, loss_bbox: 0.2314, loss_mask: 0.3134, loss: 0.9064
2022-04-15 13:26:57,131 - mmdet - INFO - Epoch [1][13850/29317]	lr: 9.689e-07, eta: 4 days, 1:44:14, time: 0.489, data_time: 0.044, memory: 11094, loss_rpn_cls: 0.0426, loss_rpn_bbox: 0.0521, loss_cls: 0.2663, acc: 92.4778, loss_bbox: 0.2355, loss_mask: 0.3292, loss: 0.9257
2022-04-15 13:27:22,109 - mmdet - INFO - Epoch [1][13900/29317]	lr: 9.689e-07, eta: 4 days, 1:44:16, time: 0.500, data_time: 0.042, memory: 11094, loss_rpn_cls: 0.0472, loss_rpn_bbox: 0.0583, loss_cls: 0.2813, acc: 92.0515, loss_bbox: 0.2438, loss_mask: 0.3240, loss: 0.9546
2022-04-15 13:27:47,049 - mmdet - INFO - Epoch [1][13950/29317]	lr: 9.689e-07, eta: 4 days, 1:44:16, time: 0.499, data_time: 0.032, memory: 11094, loss_rpn_cls: 0.0428, loss_rpn_bbox: 0.0539, loss_cls: 0.2776, acc: 92.2009, loss_bbox: 0.2387, loss_mask: 0.3271, loss: 0.9400
2022-04-15 13:28:11,387 - mmdet - INFO - Exp name: vitdet_sfp_100e_fp16_coco.py
2022-04-15 13:28:11,387 - mmdet - INFO - Epoch [1][14000/29317]	lr: 9.689e-07, eta: 4 days, 1:43:45, time: 0.487, data_time: 0.034, memory: 11094, loss_rpn_cls: 0.0442, loss_rpn_bbox: 0.0529, loss_cls: 0.2747, acc: 92.3049, loss_bbox: 0.2411, loss_mask: 0.3229, loss: 0.9358
2022-04-15 13:28:35,622 - mmdet - INFO - Epoch [1][14050/29317]	lr: 9.689e-07, eta: 4 days, 1:43:09, time: 0.485, data_time: 0.034, memory: 11094, loss_rpn_cls: 0.0426, loss_rpn_bbox: 0.0523, loss_cls: 0.2787, acc: 92.1240, loss_bbox: 0.2409, loss_mask: 0.3175, loss: 0.9319
2022-04-15 13:28:59,877 - mmdet - INFO - Epoch [1][14100/29317]	lr: 9.689e-07, eta: 4 days, 1:42:33, time: 0.485, data_time: 0.040, memory: 11094, loss_rpn_cls: 0.0456, loss_rpn_bbox: 0.0527, loss_cls: 0.2705, acc: 92.3291, loss_bbox: 0.2388, loss_mask: 0.3276, loss: 0.9353
2022-04-15 13:29:24,650 - mmdet - INFO - Epoch [1][14150/29317]	lr: 9.689e-07, eta: 4 days, 1:42:24, time: 0.495, data_time: 0.043, memory: 11094, loss_rpn_cls: 0.0430, loss_rpn_bbox: 0.0529, loss_cls: 0.2784, acc: 92.2188, loss_bbox: 0.2351, loss_mask: 0.3172, loss: 0.9265
2022-04-15 13:29:49,016 - mmdet - INFO - Epoch [1][14200/29317]	lr: 9.689e-07, eta: 4 days, 1:41:54, time: 0.487, data_time: 0.041, memory: 11094, loss_rpn_cls: 0.0417, loss_rpn_bbox: 0.0553, loss_cls: 0.2707, acc: 92.1824, loss_bbox: 0.2433, loss_mask: 0.3243, loss: 0.9353
2022-04-15 13:30:12,683 - mmdet - INFO - Epoch [1][14250/29317]	lr: 9.689e-07, eta: 4 days, 1:40:50, time: 0.473, data_time: 0.039, memory: 11094, loss_rpn_cls: 0.0414, loss_rpn_bbox: 0.0518, loss_cls: 0.2549, acc: 92.7065, loss_bbox: 0.2282, loss_mask: 0.3117, loss: 0.8880
2022-04-15 13:30:37,561 - mmdet - INFO - Epoch [1][14300/29317]	lr: 9.689e-07, eta: 4 days, 1:40:46, time: 0.497, data_time: 0.038, memory: 11094, loss_rpn_cls: 0.0460, loss_rpn_bbox: 0.0572, loss_cls: 0.2781, acc: 92.0811, loss_bbox: 0.2425, loss_mask: 0.3249, loss: 0.9486
2022-04-15 13:31:02,057 - mmdet - INFO - Epoch [1][14350/29317]	lr: 9.689e-07, eta: 4 days, 1:40:23, time: 0.490, data_time: 0.034, memory: 11094, loss_rpn_cls: 0.0419, loss_rpn_bbox: 0.0562, loss_cls: 0.2736, acc: 92.2334, loss_bbox: 0.2362, loss_mask: 0.3153, loss: 0.9230
2022-04-15 13:31:26,091 - mmdet - INFO - Epoch [1][14400/29317]	lr: 9.689e-07, eta: 4 days, 1:39:36, time: 0.480, data_time: 0.045, memory: 11094, loss_rpn_cls: 0.0422, loss_rpn_bbox: 0.0545, loss_cls: 0.2722, acc: 92.3262, loss_bbox: 0.2404, loss_mask: 0.3291, loss: 0.9384
2022-04-15 13:31:50,433 - mmdet - INFO - Epoch [1][14450/29317]	lr: 9.689e-07, eta: 4 days, 1:39:06, time: 0.487, data_time: 0.040, memory: 11094, loss_rpn_cls: 0.0421, loss_rpn_bbox: 0.0534, loss_cls: 0.2770, acc: 92.1506, loss_bbox: 0.2430, loss_mask: 0.3213, loss: 0.9368
2022-04-15 13:32:15,065 - mmdet - INFO - Epoch [1][14500/29317]	lr: 9.689e-07, eta: 4 days, 1:38:49, time: 0.492, data_time: 0.038, memory: 11094, loss_rpn_cls: 0.0406, loss_rpn_bbox: 0.0528, loss_cls: 0.2715, acc: 92.5068, loss_bbox: 0.2316, loss_mask: 0.3158, loss: 0.9123
2022-04-15 13:32:39,647 - mmdet - INFO - Epoch [1][14550/29317]	lr: 9.689e-07, eta: 4 days, 1:38:31, time: 0.492, data_time: 0.037, memory: 11094, loss_rpn_cls: 0.0447, loss_rpn_bbox: 0.0557, loss_cls: 0.2713, acc: 92.3503, loss_bbox: 0.2372, loss_mask: 0.3180, loss: 0.9270
2022-04-15 13:33:03,946 - mmdet - INFO - Epoch [1][14600/29317]	lr: 9.689e-07, eta: 4 days, 1:37:59, time: 0.486, data_time: 0.037, memory: 11094, loss_rpn_cls: 0.0439, loss_rpn_bbox: 0.0535, loss_cls: 0.2717, acc: 92.2087, loss_bbox: 0.2433, loss_mask: 0.3181, loss: 0.9306
2022-04-15 13:33:28,399 - mmdet - INFO - Epoch [1][14650/29317]	lr: 9.689e-07, eta: 4 days, 1:37:34, time: 0.489, data_time: 0.038, memory: 11094, loss_rpn_cls: 0.0428, loss_rpn_bbox: 0.0557, loss_cls: 0.2754, acc: 92.1790, loss_bbox: 0.2400, loss_mask: 0.3189, loss: 0.9328
2022-04-15 13:33:53,183 - mmdet - INFO - Epoch [1][14700/29317]	lr: 9.689e-07, eta: 4 days, 1:37:24, time: 0.496, data_time: 0.041, memory: 11094, loss_rpn_cls: 0.0426, loss_rpn_bbox: 0.0566, loss_cls: 0.2847, acc: 91.9180, loss_bbox: 0.2505, loss_mask: 0.3149, loss: 0.9494
2022-04-15 13:34:17,066 - mmdet - INFO - Epoch [1][14750/29317]	lr: 9.689e-07, eta: 4 days, 1:36:32, time: 0.478, data_time: 0.039, memory: 11094, loss_rpn_cls: 0.0417, loss_rpn_bbox: 0.0539, loss_cls: 0.2736, acc: 92.4700, loss_bbox: 0.2381, loss_mask: 0.3213, loss: 0.9285
